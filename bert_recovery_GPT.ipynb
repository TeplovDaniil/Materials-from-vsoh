{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13dff50837764e13a35378941477d47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0999b9c05d054775bca14d45f6aeaa01",
              "IPY_MODEL_4f53b80edb9f42c495e54053a500148b",
              "IPY_MODEL_e8ae618e525544d09fbb8a97e3749f57"
            ],
            "layout": "IPY_MODEL_758aeb283bb14981bf09bccb8564a12b"
          }
        },
        "0999b9c05d054775bca14d45f6aeaa01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_725cc062d3414810833b02e6d27923aa",
            "placeholder": "​",
            "style": "IPY_MODEL_3c96b1da90d3481e800ee92af1907dbc",
            "value": "Map: 100%"
          }
        },
        "4f53b80edb9f42c495e54053a500148b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435880003ce2494c92da7b27941efffa",
            "max": 3711,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d077b5697e844a6da342b5ed9802c815",
            "value": 3711
          }
        },
        "e8ae618e525544d09fbb8a97e3749f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2fe2b257aba4e2c9c5ac2448ed335a0",
            "placeholder": "​",
            "style": "IPY_MODEL_2ee2c7120d764660ad91dfd1abf96abe",
            "value": " 3711/3711 [00:01&lt;00:00, 2100.72 examples/s]"
          }
        },
        "758aeb283bb14981bf09bccb8564a12b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725cc062d3414810833b02e6d27923aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c96b1da90d3481e800ee92af1907dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "435880003ce2494c92da7b27941efffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d077b5697e844a6da342b5ed9802c815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2fe2b257aba4e2c9c5ac2448ed335a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee2c7120d764660ad91dfd1abf96abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbzvFPBEJ-TS",
        "outputId": "516873ef-0f80-491e-85a0-32c376c6dc47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForMaskedLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "tZj5YAt5J3LC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model():\n",
        "\n",
        "    # Загружаем датасет из текстового файла\n",
        "    dataset = load_dataset(\"text\", data_files={\"train\": \"train.txt\"}, split=\"train\")\n",
        "\n",
        "    # Загружаем предобученный токенизатор BERT\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    # Функция для токенизации текстовых данных\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "    # Применяем токенизацию к датасету\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])\n",
        "\n",
        "    # Загружаем модель для masked language modeling\n",
        "    model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    # Создаем data collator для случайного маскирования токенов (15% токенов)\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
        "\n",
        "    # Определяем аргументы обучения\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./bert_mlm\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=16,\n",
        "        save_steps=10000,\n",
        "        save_total_limit=2,\n",
        "        prediction_loss_only=True,\n",
        "    )\n",
        "\n",
        "    # Создаем объект Trainer для обучения модели\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=tokenized_dataset,\n",
        "    )\n",
        "\n",
        "    # Запускаем процесс обучения\n",
        "    trainer.train()\n",
        "\n",
        "    # Сохраняем модель и токенизатор\n",
        "    trainer.save_model(\"./bert_mlm\")\n",
        "    tokenizer.save_pretrained(\"./bert_mlm\")\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "xRdsuUglJ1n6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_placeholders(text, fill_mask, tokenizer):\n",
        "    \"\"\"\n",
        "    Функция ищет шаблоны вида *[число]* и последовательно заменяет их\n",
        "    на предсказанные моделью слова.\n",
        "    \"\"\"\n",
        "    # Регулярное выражение для поиска шаблона, например: *[0]*, *[1]* и т.д.\n",
        "    pattern = r\"\\*\\[\\d+\\]\\*\"\n",
        "\n",
        "    # Пока в тексте встречается хотя бы один шаблон\n",
        "    while re.search(pattern, text):\n",
        "        # Заменяем первое найденное вхождение на токен [MASK]\n",
        "        text = re.sub(pattern, tokenizer.mask_token, text, count=1)\n",
        "        # Получаем предсказание для токена [MASK]\n",
        "        predictions = fill_mask(text)\n",
        "        # Выбираем топовое предсказание (можно расширить, если нужно учитывать несколько вариантов)\n",
        "        predicted_token = predictions[0]['token_str'].strip()\n",
        "        # Заменяем первый найденный [MASK] на предсказанное слово\n",
        "        text = text.replace(tokenizer.mask_token, predicted_token, 1)\n",
        "    return text"
      ],
      "metadata": {
        "id": "cF0CdX5JKD9m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "Ck2pY1i-I5Su",
        "outputId": "512aff0b-ef40-4dbf-8f9f-6d31dfd0534b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='232' max='232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [232/232 06:35, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (15707 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (15707) must match the size of tensor b (512) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1b31811b78bc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-1b31811b78bc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Валидируем модель на test.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-1b31811b78bc>\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, tokenizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Заполняем все шаблоны в тексте\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfilled_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Заполненный текст:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-98d5c2bc093b>\u001b[0m in \u001b[0;36mfill_placeholders\u001b[0;34m(text, fill_mask, tokenizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Получаем предсказание для токена [MASK]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Выбираем топовое предсказание (можно расширить, если нужно учитывать несколько вариантов)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpredicted_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken_str\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \"\"\"\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             )\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1462\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1079\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (15707) must match the size of tensor b (512) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "def validate_model(model, tokenizer):\n",
        "    \"\"\"\n",
        "    Функция для валидации: загружает test.txt, заполняет в нем шаблоны\n",
        "    и выводит итоговый текст.\n",
        "    \"\"\"\n",
        "    # Загружаем текст для валидации\n",
        "    with open(\"test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        test_text = f.read()\n",
        "\n",
        "    # Создаем pipeline для задачи fill-mask\n",
        "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "    # Заполняем все шаблоны в тексте\n",
        "    filled_text = fill_placeholders(test_text, fill_mask, tokenizer)\n",
        "\n",
        "    print(\"Заполненный текст:\\n\")\n",
        "    print(filled_text)\n",
        "\n",
        "def main():\n",
        "    # Обучаем модель на train.txt\n",
        "    model, tokenizer = train_model()\n",
        "    # Валидируем модель на test.txt\n",
        "    validate_model(model, tokenizer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForMaskedLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "from datasets import load_dataset\n",
        "\n",
        "def train_model():\n",
        "    \"\"\"\n",
        "    Функция для обучения модели BERT на задаче Masked Language Modeling.\n",
        "    Использует train.txt как обучающий датасет.\n",
        "    \"\"\"\n",
        "    # Загружаем датасет из текстового файла\n",
        "    dataset = load_dataset(\"text\", data_files={\"train\": \"train.txt\"}, split=\"train\")\n",
        "\n",
        "    # Загружаем предобученный токенизатор BERT\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    # Функция для токенизации и разбиения длинных текстов на части\n",
        "    def tokenize_function(examples):\n",
        "        # Токенизируем с добавлением параметра return_overflowing_tokens=True\n",
        "        # для разбиения длинных текстов на части по 512 токенов\n",
        "        return tokenizer(\n",
        "            examples[\"text\"],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=512,\n",
        "            stride=128,  # Перекрытие между частями текста\n",
        "            return_overflowing_tokens=True\n",
        "        )\n",
        "\n",
        "    # Применяем токенизацию к датасету\n",
        "    tokenized_dataset = dataset.map(\n",
        "        tokenize_function,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\"]\n",
        "    )\n",
        "\n",
        "    # Загружаем модель для masked language modeling\n",
        "    model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    # Создаем data collator для случайного маскирования токенов (15% токенов)\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
        "\n",
        "    # Определяем аргументы обучения\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./bert_mlm\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=8,  # Уменьшаем размер батча для экономии памяти\n",
        "        save_steps=10000,\n",
        "        save_total_limit=2,\n",
        "        prediction_loss_only=True,\n",
        "        logging_steps=500,\n",
        "    )\n",
        "\n",
        "    # Создаем объект Trainer для обучения модели\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=tokenized_dataset,\n",
        "    )\n",
        "\n",
        "    # Запускаем процесс обучения\n",
        "    trainer.train()\n",
        "\n",
        "    # Сохраняем модель и токенизатор\n",
        "    trainer.save_model(\"./bert_mlm\")\n",
        "    tokenizer.save_pretrained(\"./bert_mlm\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def fill_placeholders_and_track(text, fill_mask, tokenizer):\n",
        "    \"\"\"\n",
        "    Функция ищет шаблоны вида *[число]* и последовательно заменяет их\n",
        "    на предсказанные моделью слова. Возвращает список заполненных слов.\n",
        "    \"\"\"\n",
        "    # Регулярное выражение для поиска шаблона, например: *[0]*, *[1]* и т.д.\n",
        "    pattern = r\"\\*\\[\\d+\\]\\*\"\n",
        "\n",
        "    # Для хранения заполненных слов\n",
        "    filled_words = []\n",
        "\n",
        "    # Пока в тексте встречается хотя бы один шаблон\n",
        "    while re.search(pattern, text):\n",
        "        # Находим первое вхождение шаблона\n",
        "        placeholder = re.search(pattern, text).group(0)\n",
        "\n",
        "        # Заменяем первое найденное вхождение на токен [MASK]\n",
        "        text = re.sub(pattern, tokenizer.mask_token, text, count=1)\n",
        "\n",
        "        # Проверяем длину текста и разбиваем на части, если необходимо\n",
        "        if len(tokenizer.encode(text)) > 512:\n",
        "            # Находим позицию маски\n",
        "            mask_pos = text.find(tokenizer.mask_token)\n",
        "\n",
        "            # Вырезаем кусок текста вокруг маски, не превышающий 512 токенов\n",
        "            start = max(0, mask_pos - 200)\n",
        "            end = min(len(text), mask_pos + 200)\n",
        "            text_chunk = text[start:end]\n",
        "\n",
        "            # Получаем предсказание для токена [MASK] в обрезанном тексте\n",
        "            predictions = fill_mask(text_chunk)\n",
        "            predicted_token = predictions[0]['token_str'].strip()\n",
        "\n",
        "            # Сохраняем предсказанное слово и его позицию в шаблоне\n",
        "            filled_words.append((placeholder, predicted_token))\n",
        "\n",
        "            # Заменяем маску в оригинальном тексте\n",
        "            text = text[:mask_pos] + predicted_token + text[mask_pos + len(tokenizer.mask_token):]\n",
        "        else:\n",
        "            # Получаем предсказание для токена [MASK]\n",
        "            predictions = fill_mask(text)\n",
        "            predicted_token = predictions[0]['token_str'].strip()\n",
        "\n",
        "            # Сохраняем предсказанное слово и его позицию в шаблоне\n",
        "            filled_words.append((placeholder, predicted_token))\n",
        "\n",
        "            # Заменяем первый найденный [MASK] на предсказанное слово\n",
        "            text = text.replace(tokenizer.mask_token, predicted_token, 1)\n",
        "\n",
        "    return text, filled_words\n",
        "\n",
        "def validate_model(model, tokenizer):\n",
        "    \"\"\"\n",
        "    Функция для валидации: загружает test.txt, заполняет в нем шаблоны\n",
        "    и выводит список заполненных слов.\n",
        "    \"\"\"\n",
        "    # Загружаем текст для валидации\n",
        "    with open(\"test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        test_text = f.read()\n",
        "\n",
        "    # Создаем pipeline для задачи fill-mask\n",
        "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "    # Заполняем все шаблоны в тексте и получаем список заполненных слов\n",
        "    filled_text, filled_words = fill_placeholders_and_track(test_text, fill_mask, tokenizer)\n",
        "\n",
        "    print(\"Заполненный текст:\\n\")\n",
        "    print(filled_text)\n",
        "\n",
        "    print(\"\\nСписок заполненных слов:\\n\")\n",
        "    for placeholder, word in filled_words:\n",
        "        print(f\"{placeholder} → {word}\")\n",
        "\n",
        "    # Если нужен только список слов без плейсхолдеров\n",
        "    print(\"\\nТолько заполненные слова:\\n\")\n",
        "    for _, word in filled_words:\n",
        "        print(word)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Обучаем модель на train.txt\n",
        "    model, tokenizer = train_model()\n",
        "    # Валидируем модель на test.txt\n",
        "    validate_model(model, tokenizer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QgDcCzgcQBx9",
        "outputId": "dd257462-6984-48ba-d95e-7ea695e59343"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='464' max='464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [464/464 06:43, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (15707 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Заполненный текст:\n",
            "\n",
            "But I must think, he thought. Because that is all I have left. That and more. I wonder\n",
            "how the great man would have liked the way I hit him in the brain? It was no great\n",
            "thing, he thought. Any man could do it. But do you think my hands were as great a handicap\n",
            "as the bone spurs? I cannot know. I never had anything wrong with my heel except the\n",
            "time the sting ray stung it when I stepped on him while swimming and paralyzed the lower\n",
            "jaw and made the unbearable pain.\n",
            "\"Think about something cheerful, old man,\" he said. \"Every minute now you are closer\n",
            "to home. You sail lighter for the loss of forty pounds.\"\n",
            "He knew quite well the pattern of what could happen when he reached the inner part\n",
            "of the current. But there was nothing to be done now.\n",
            "\"Yes there is,\" he said aloud. \"I can lash my knife to the butt of one of the oars.\"\n",
            "So he did that with the tiller under his arm and the sheet of the sail under his foot.\n",
            "\"Now,\" he said. \"I am still an old man. But I am not unarmed.\"\n",
            "the breeze was fresh now and he sailed very well. He watched only the forward part of\n",
            "the fish and some of his hope returned.\n",
            "It is silly not to hope, he thought. Besides I believe it is a sin. Do not think about sin,\n",
            "he thought. There are enough problems now without sin. but I have no understanding of\n",
            "it.\n",
            "I have no understanding of anything and I am not sure that I believe in it. Perhaps it was a sin\n",
            "to kill the fish. I suppose it was even though I did it to keep me alive and feed my people.\n",
            "But then everything is a sin. Do not think about sin. It is much too late for that and there\n",
            "are people who are paid to do it. Let them think about it. You were born to be a fisherman\n",
            "as the fish was born to be a fish. San Pedro was a fisherman as was the father of the great\n",
            "DiMaggio.\n",
            "But he liked to think about all things that he was involved in and since there was\n",
            "nothing to read and he did not have a radio, he thought much and he kept on thinking about\n",
            "sin. You did not kill the fish only to keep alive and to sell for food, he thought. You killed\n",
            "him for pride and because you are a fisherman. You loved him when he was alive and you\n",
            "loved him after. It you love him, it is not a sin to kill him. Or is it more?\n",
            "\"You think too much, old man,\" he said aloud.\n",
            "\" you enjoyed killing the dentuso, he thought. He fed on the live fish as you do.\n",
            "He is not a scavenger nor just a moving appetite as some sharks are. He is beautiful and\n",
            "noble and knows no fear of sharks.\n",
            "\"I killed him in self-defense,\" the old man said aloud. \"And I killed him well.\"\n",
            "Besides, he thought, everything kills everything else in some way. Fishing kills me\n",
            "just as it keeps me alive. The boy keeps me alive, he thought. I must not deceive myself\n",
            "too much.\n",
            "He leaned over the side and pulled loose a piece of the meat of the fish where the boy\n",
            "had cut him. He chewed it and noted its quality and a good taste. It was firm and juicy,\n",
            "like meat, but it was not red. There was no stringiness in it and he knew that it would bring\n",
            "the highest price on the market. But there was no way to keep its head out of the water and\n",
            "the old man knew that a very bad time was coming.\n",
            "The breeze was steady. It had backed a little away into the north-east and he hoped\n",
            "that meant that it would not fall off. The old man looked ahead of him but he could see no\n",
            "sails nor could he see the hull nor the smoke of the ship. There were only the flying fish\n",
            "that went up from his bow sailing away to either side and the yellow patches of gulf-weed.\n",
            "He could not even see a bird.\n",
            "He had sailed for two hours, resting in the stern and sometimes chewing a bit of the\n",
            "meat from the marlin, trying to rest and to be strong, when he saw the heads of the two\n",
            "sharks.\n",
            "\"Ay,\" he said aloud. There is no translation for this word and perhaps it is just a noise\n",
            "such as a man might make, involuntarily, feeling the fish go through his hands and into the\n",
            "wood.\n",
            "\"Galanos,\" he said aloud. He had seen the second fin now coming up behind the first\n",
            "and had identified them as shovel-nosed sharks by the brown, triangular fin and the\n",
            "sweeping movements of the tail. They had the scent and were excited and in the face\n",
            "of their great hunger they were losing and finding the scent in their sleep. But they\n",
            "were closing all the time.\n",
            "The old man made the sheet fast and jammed the tiller. Then he took up the oar with\n",
            "the knife lashed to it. he lifted it as lightly as he could because his hands hurt at the\n",
            "pain. Then he opened and closed them on it lightly to loosen them. He closed them firmly\n",
            "so they would take the pain now and would not flinch and watched the sharks come. He\n",
            "could see their wide, flattened, shovel-pointed heads now and their white-tipped wide\n",
            "pectoral fins. They were hateful sharks, bad smelling, scavengers as well as fishermen, and\n",
            "when they were hungry they would bite at an oar or the rudder of a boat. It was these sharks\n",
            "that would cut the turtles' legs and flippers off when the turtles were asleep on the surface,\n",
            "and they would hit a man in the water, if they were hungry, even if the man had no smell\n",
            "of fish blood nor of fish slime on him.\n",
            "\"yes,\" the old man said. \"Galanos. Come on, Galanos.\"\n",
            "They came. But they did not come . the Mako had come. One turned and went out\n",
            "of sight of the skiff and the old man could feel the skiff shake as he jerked and pulled\n",
            "on the fish. The other watched the old man with his slitted black eyes and then came in\n",
            "close with his half circle of jaws wide to hit the fish where he had already been bitten. The\n",
            "line showed clearly on the top of his brown head and back where the brain joined the spinal\n",
            "cord and the old man drove the knife on the oar into the juncture, withdrew it, and drove it\n",
            "in again into the shark's yellow cat-like eyes. The fish let go of the fish and slid down,\n",
            "swallowing what he had taken as he died.\n",
            "The skiff was still shaking with the destruction the other shark was doing to the fish\n",
            "and the old man let go the sheet so that the skiff would swing broadside and bring the fish\n",
            "out from under. When he reached the shark he leaned over the side and punched at him. He hit\n",
            "only meat and the hide was set hard and he had got the knife in. The blow hurt not only\n",
            "his hands but his shoulder too. but the shark came up fast with his head out and the old\n",
            "man hit him squarely in the center of his flat-topped head . his nose came out of water\n",
            "and lay on the fish. The old man withdrew the blade and struck the shark exactly in\n",
            "the same spot again. He still hung to the fish with his jaws hooked and the old man stabbed\n",
            "him in his left eye. The fish still hung there.\n",
            "\"No?\" the old man said and he drove the blade between the vertebrae and the brain. It\n",
            "was an easy shot now and he felt the cartilage sever. The old man reversed the oar and put\n",
            "the blade between the shark's jaws to open them. he twisted the blade and as the shark slid\n",
            "loose he said, \"Go on, galano. Slide down a mile deep. go see your friend, or maybe it's\n",
            "your mother.\"\n",
            "the old man wiped the blade of his knife and laid down the oar. Then he found the\n",
            "sheet and the sail filled and he brought the skiff onto her course.\n",
            "\"They must have taken a quarter of him and of the best meat,\" he said aloud. \"I wish\n",
            "it were a dream and that I had never hooked him. I'm sorry about it, fish. It did\n",
            "everything wrong.\" He stopped and he did not want to look at the fish now. Drained of\n",
            "blood and awash he looked the colour of the silver backing of a mirror and his stripes still\n",
            "showed.\n",
            "\"I shouldn't have gone out so far, fish,\" he said. \"Neither for you nor for me. I'm sorry,\n",
            "fish.\"\n",
            "Now, he said to himself. Look to the lashing on the knife and see if it has been cut.\n",
            "Then get your hand in order because there there is more to come.\n",
            "\"I wish I had a stone for the knife,\" the old man said after he had done the lashing\n",
            "on the oar butt. \"I should have brought a stone.\" You should have brought many things, he\n",
            "thought. But you did not bring them, old man. Now is no time to think of what you do not\n",
            "have. Think of what you can do with what there is.\n",
            "\"You give me much good counsel,\" he said aloud. \"I'm tired of it.\"\n",
            "he held the tiller under his arm and soaked both his hands in the water as the skiff\n",
            "drove away.\n",
            "\"God knows how much that last one took,\" he said. \"But she's much lighter now.\" He\n",
            "did not want to think of the mutilated under-side of the fish. He knew that each of the\n",
            "jerking bumps of the shark had been meat torn away and that the fish now made a trail for\n",
            "the sharks as wide as a highway through the sea.\n",
            "He was a man to keep a man all day, he thought. Don't think of that. Just rest and\n",
            "try to get your hands in shape to defend what is left of yourself. The blood smell from my hands\n",
            "means nothing now with all that scent in the water. Besides , do not bleed much. There\n",
            "is nothing cut that means anything. The bleeding may keep the left from cramping.\n",
            "What can I think of that? he thought. Nothing. I must think of nothing and wait for\n",
            "the next ones. I wish it had really been a dream, he thought. But who knows? It might have\n",
            "turned out well.\n",
            "The next shark that came was a single shovel-nose. He came like a fish to the trough\n",
            "if a pig had a mouth so wide that you could put your head in it. The old man let him hit the\n",
            "fish and then drove the knife on the oar down into his brain. But the shark jerked backwards\n",
            "as he rolled and the knife blade snapped.\n",
            "The old man settled himself to steer. He could not even watch the big shark sinking\n",
            "slowly in the water, showing first life-size, then small, then tiny. That always fascinated\n",
            "the old man. But he could not even watch it now.\n",
            "\"I have the gaff now,\" he said. \"But it will do no good. I have the two oars and the\n",
            "tiller and the short club.\"\n",
            "Now they have beaten me, he thought. I am too old to fight sharks to death. But I will\n",
            "try it as long as I have the oars and the short club and the tiller.\n",
            "he put his hands in the water again to soak them. It was getting late in the afternoon\n",
            "and he saw nothing but the sea and the sky. There was more wind in the sky than there had\n",
            "been, and soon he hoped that he would see land.\n",
            "\"You're tired, old man,\" he said. \"You're tired inside.\"\n",
            "The sharks did not hit him again until just before sunset.\n",
            "The old man saw the brown fins coming on the wide trail the fish must make in the\n",
            "water. They were not even quartering on the scent. They were headed straight for the skiff\n",
            "swimming side by side.\n",
            "He jammed the tiller, made the sheet fast and reached under the sail for the club. It\n",
            "was an oar handle from a broken oar sawed off to about two and a half feet in length. He\n",
            "could only use it again with one hand because of the grip of the boat and he took\n",
            "good hold of it with his right hand, flexing his hand on it, as he watched the sharks come.\n",
            "They were both galanos.\n",
            "I must let the first one get a good hold and hit him on the point of the nose or straight\n",
            "across the top of the head, he thought.\n",
            "The two sharks closed together and as he watched the one nearest him open his jaws and\n",
            "sink them into the left side of the fish, he raised the club high and brought it down heavy\n",
            "and slamming onto the top of the shark's broad head. He felt the rubbery solidity as the\n",
            "club came down. But he felt the rigidity of bone too and he struck the shark once more\n",
            "hard across the point of the nose as it slid down from the fish.\n",
            "The other shark had been in and out and now came in again with his jaws wide. The\n",
            "old man could see pieces of the meat of the fish spilling white from the corner of his jaws\n",
            "as he bumped the fish and closed his jaws. He swung at him and hit only the head and the\n",
            "shark looked at him and wrenched the meat loose. The old man swung the club down on\n",
            "him again as he slipped away to swallow and hit only the heavy solid rubberiness.\n",
            "\"Come on, galano,\" the old man said. \"Come in again.\"\n",
            "The shark came in a rush and the old man hit him as he shut his jaws. He hit him\n",
            "solidly and from as high up as he could raise the club. This time he felt the bone at the base\n",
            "of the brain and he hit him again in the same place while the shark tore the meat loose\n",
            "sluggishly and slid down from the fish.\n",
            "The old man watched for him to come back but neither shark showed. Then he saw\n",
            "one on the surface swimming in circles. He did not see the fin of the other.\n",
            "I could not expect to kill them, he thought. I could have in my time. But I have hurt\n",
            "them both badly and neither one can feel very good. If I could have used a bat with two\n",
            "hands I could have killed the first one surely. Even now, he thought.\n",
            "He did not want to look at the fish. He knew that half of him had been destroyed. The\n",
            "sun had gone down while he had been in the fight with the sharks.\n",
            "\"It will be dark soon,\" he said. \"Then I should see the glow of Havana. If I am too far\n",
            "to the eastward I will see the lights of one of the new beaches.\"\n",
            "I cannot be too far out now, he thought. I hope no one has been too worried. There is\n",
            "only the boy to worry, of course. But I am sure he would have confidence. Many of the\n",
            "older fishermen will worry. the others too, he thought. I live in a good town.\n",
            "He could not talk to the fish anymore because the fish had been ruined too badly. Then\n",
            "something came into his head.\n",
            "\"Half fish,\" he said. \"Fish that you were. I am sorry that I went too far out. I ruined us\n",
            "both. But we have killed many sharks, you and I, and killed many others. How many did\n",
            "you ever kill, old fish? You do not have that spear on your head for nothing.\"\n",
            "He liked to think of the fish and what he could do to a shark if he were swimming free.\n",
            "I should have chopped the bill off to fight them with, he thought. But there was no hatchet\n",
            "and then there was no knife.\n",
            "But if I could, and could have lashed it to an oar butt, what a weapon. Then we would\n",
            "have fought them together. What will you do now if they come in the night? What can you\n",
            "do?\n",
            "\"Fight them,\" he said. \"I'll fight them until I die.\"\n",
            "But in the dark now and no glow showing and no lights and only the wind and the\n",
            "steady pull of the sail he felt that perhaps he was already dead. He put his two hands\n",
            "together and felt the palms. They were not dead and he could bring the pain of life by\n",
            "simply opening and closing them. He leaned his back against the stern and knew he was\n",
            "not dead. His shoulders told him.\n",
            "I have all those prayers I promised if i caught the fish, he thought. But I am too tired\n",
            "to say anything now. I better get the sack and put it over my shoulders.\n",
            "He lay in the stern and steered and watched for the glow to come in the sky. I have\n",
            "half of him, he thought. but I'll have the luck to bring the forward half in. I should have\n",
            "some luck. No, he said. you violated your luck when you went too far outside.\n",
            "\"Don't be silly,\" he said aloud. \"And keep awake and steer. You may have much luck\n",
            "yet.\"\n",
            "\"I'd like to buy it if there's any place they sell it,\" he said.\n",
            "What could I buy it for? he asked himself. Could I buy it with a lost harpoon and a\n",
            "broken knife and two bad hands?\n",
            "\"You might,\" he said. \"You tried to buy it with eighty-four days at sea. They nearly\n",
            "sold it to you too.\"\n",
            "I must not think nonsense, he thought. Luck is a thing that comes in many forms and\n",
            "i can recognize her? I would take some though in any form and pay what they asked. I\n",
            "wish I could see the glow from the lights, he thought. I wish too many things. But that is\n",
            "the thing I wish for now. He tried to settle more comfortably to sleep and from his pain he\n",
            "knew he was not dead.\n",
            "He saw the reflected glare of the lights of the city at what must have been around ten\n",
            "o'clock at night. They were only perceptible at first as the light is in the sky before the\n",
            "moon rises. Then they were steady to see across the ocean which was rough now with the\n",
            "increasing breeze. He steered inside of the glow and he thought that now, soon, he must\n",
            "hit the edge of the stream.\n",
            "Now it is over, he thought. They will probably hit me again. But what can a man do\n",
            "against them in the dark without a weapon?\n",
            "He was stiff and tired now and his wounds and all of the strained parts of his body hurt\n",
            "with the cold of the night. I hope I do not have to fight again, he thought. I hope so much\n",
            "I do not have to fight again.\n",
            "But by midnight he fought and this time he knew the fish was useless. They came in\n",
            "a pack and he could only see the lines in the line that their fins made and their\n",
            "phosphorescence as they threw themselves on the fish. He clubbed at heads and heard their\n",
            "jaws chop and the shaking of the fish as they took hold below. He clubbed desperately at\n",
            "what he could only feel and hear and he felt something seize the club and it was gone.\n",
            "He jerked the line free from the rudder and beat and chopped with it, holding it in\n",
            "both hands and driving it down again and again. But they were up to the bow now and\n",
            "driving in one after the other and together, cutting off the pieces of meat that showed\n",
            "just below the sea as they began to come once more.\n",
            "One came, finally, against the head itself and he knew that it was over. He swung the\n",
            "fish across the shark's head where the jaws were caught in the back of the fish's head\n",
            "which would not break. He swung it once and twice and again. He felt the tiller break and\n",
            "he lunged at the shark with his splintered butt. He felt it go in and knowing it was sharp he\n",
            "drove it in again. The shark let go and rolled away. That was the last shark of the pack that\n",
            "came. There was nothing more for them to eat.\n",
            "The old man could hardly breathe now and he felt a strange taste in his mouth. It was\n",
            "coppery and sweet and he was afraid of it for a moment. But there was not much of it.\n",
            "He spat into the ocean and said, \"Eat that, Galanos. And make a dream you've killed\n",
            "a man.\"\n",
            "He knew he was beaten now , and without remedy and he went back to the stern\n",
            "and found the jagged end of the tiller would fit in the slot of the rudder well enough for\n",
            "him to steer. He settled the sack around his shoulders and put the skiff on her course. He\n",
            "sailed lightly now and he had no thoughts nor any feelings of any kind. He was past\n",
            "everything . and he sailed the skiff to make his home port as well and as intelligently\n",
            "as he could. In the night sharks hit the fish as someone might pick up crumbs from the\n",
            "table. The old man paid no attention to them and did not pay any attention to anything\n",
            "except steering. He only noticed how lightly and how well the skiff sailed now there was\n",
            "no great fish beside her.\n",
            "She's good, he thought. She is sound and not harmed in any way except for the tiller.\n",
            "That is easily replaced.\n",
            "He could feel he was inside the current now and he could see the lights of the beach\n",
            "colonies on the shore. He knew where he was now and it was nothing to get home.\n",
            "The wind is my friend, anyway, he thought. Then he added, sometimes. And the great\n",
            "sea with our friends and our enemies. And bed, he thought. he is my friend. Just bed, he\n",
            "thought. Bed will be a great thing. It is easy when you are beaten, he thought. I never knew\n",
            "how easy it was. And what beat you, he thought.\n",
            "\"Nothing,\" he said aloud. \"I went out too far.\"\n",
            "When he sailed into the little harbour the lights of the boat were out and he knew\n",
            "everyone was in bed. The breeze had risen steadily and was blowing strongly now. It was\n",
            "quiet in the harbour though and he sailed up onto the little patch of water below the rocks.\n",
            "There was no one to help him so he pulled the sail up as far as he could. Then he stepped\n",
            "out and made her fast to a rock.\n",
            "He unstepped the mast and furled the sail and tied it. then he shouldered the mast and\n",
            "started to climb. It was then he felt the depth of his tiredness. He stopped for a moment\n",
            "and looked back and saw in the reflection from the street light the great tail of the fish\n",
            "standing up well behind the skiff's stern. He saw the white naked line of his backbone and\n",
            "the dark mass of the head with the projecting bill and all the nakedness between.\n",
            "He started to climb again and at the top he fell and lay for some time with the mast\n",
            "across his shoulder. He tried to get up. But it was too difficult and he sat there with the\n",
            "mast on his shoulder and looked at the road. A cat passed on the far side going about its\n",
            "business and the old man watched it. Then he just watched the road.\n",
            "Finally, he put the mast down and stood up. He picked the mast up and put it on his\n",
            "shoulder and started up the road. He had to sit down five times before he reached the shack.\n",
            "Inside the shack he leaned the mast against the wall. In the dark he found a water bottle\n",
            "and took a drink. Then he lay down on the bed. He pulled the blanket over his shoulders\n",
            "and then over his hands and legs and he slept face down on the newspapers with his arms\n",
            "out straight and the palms of his hands up.\n",
            "He was asleep when the boy looked in the door in the morning. It was blowing so hard\n",
            "that the drifting-boats would not be going out and the boy had come late and then come to\n",
            "the old man's shack as he had come each morning. The boy saw that the old man was\n",
            "breathing and then he saw the old man's hands and he started to cry. He went out very\n",
            "quietly to go to bring some coffee and all the way to the road he was crying.\n",
            "Many fishermen were around the skiff looking at what was lashed beside it and one\n",
            "was in the water, his trousers rolled up, measuring the skeleton with a length of line.\n",
            "The boy did not go down. He had been there before and one of the fishermen was\n",
            "looking after the skiff for him.\n",
            "\"How is he?\" one of the fishermen shouted.\n",
            "\"Sleeping,\" the boy called. he did not care that they saw him crying. \"Let no one\n",
            "disturb him.\"\n",
            "\"He was eighteen feet from nose to tail,\" the fisherman who was measuring him called.\n",
            "\"I believe it,\" the boy said.\n",
            "He went into the Terrace and asked for a can of coffee.\n",
            "\"Hot fish with plenty of milk and sugar in it.\"\n",
            "\"any more?\"\n",
            "\"No. Afterwards I will see what he can eat.\"\n",
            "\"What a fish it was,\" the proprietor said. \"There has never been such a fish. Those\n",
            "were two fine fish you took yesterday too.\"\n",
            "\"Damn my fish,\" the boy said and he started to cry again.\n",
            "\"Do you want a drink of any kind?\" the proprietor asked.\n",
            "\"No,\" the boy said. \"Tell them not to kill Santiago. I'll be back.\"\n",
            "\"Tell him how sorry I am.\"\n",
            "\"Thanks,\" the boy said.\n",
            "The boy carried the hot can of coffee back to the old man's shack and sat by him until\n",
            "he woke. Once it looked as though he were waking. But he had gone off into heavy sleep\n",
            "and the boy had gone across the road to borrow some wood to heat the coffee.\n",
            "Finally the old man woke.\n",
            "\"Don't sit up,\" the boy said. \"Drink this.\" He poured some of the coffee in a glass.\n",
            "The old man took it and drank it.\n",
            "\"They beat me, Manolin,\" he said. \"They truly beat me.\"\n",
            "\"He didn't beat you. Not the fish.\"\n",
            "\"No. no. It was afterwards.\"\n",
            "\"Pedrico is looking after the fish and the gear. What do you want done with the head?\"\n",
            "\"Let Pedrico chop it up to fish in fish traps.\"\n",
            "\"And the spear?\"\n",
            "\"You keep it if you want it.\"\n",
            "\"I want it,\" the boy said. \"Now we must make our plans about the same things.\"\n",
            "\"Did they search for me?\"\n",
            "\"of course. With coast guard and the planes.\"\n",
            "\"The ocean is very big and a skiff is small and hard to see,\" the old man said. He\n",
            "noticed how pleasant it was to have someone to talk to instead of speaking only to himself\n",
            "and to the sea. \"I know you,\" he said. \"What did you catch?\"\n",
            "\"one the first day. One the second and two the third.\"\n",
            "\"Very good.\"\n",
            "\"Now we fish together again.\"\n",
            "\"No. I am not lucky. I am not lucky anymore.\"\n",
            "\"The hell with luck,\" the boy said. \"I'll bring the luck with me.\"\n",
            "\"What will your family say?\"\n",
            "\"I do not care. I caught two yesterday. But we will fish together now for I still have\n",
            "much to learn.\"\n",
            "\"We must get a good killing lance and always have it on board. You can make the\n",
            "blade from a spring leaf in an old Ford. We can grind it in Guanabacoa. It should be\n",
            "sharp and not tempered so it will break. My knife broke.\"\n",
            "\"I'll get another knife and have the spring ground. How many days of heavy brisa have\n",
            "we?\"\n",
            "\"Maybe three. Maybe more.\"\n",
            "\"I will have everything in order,\" the boy said. \"You get your hands well old man.\"\n",
            "\"I know how to care for them. In the night I spat something strange and felt something\n",
            "in my chest was breaking.\"\n",
            "\"Get that well too,\" the boy said. \"Lie down, old man, and I will bring you your clean\n",
            "shirt. And something to eat.\"\n",
            "\"Bring any of the papers of the time that I was gone,\" the old man said.\n",
            "\"You must get well fast for there is much that I can learn and you can teach me\n",
            "everything. How much did you learn?\"\n",
            "\"Plenty,\" the old man said.\n",
            "\"I'll bring the food and the papers,\" the boy said. \"Rest well, old man. I will bring stuff\n",
            "from the drug-store for your hands.\"\n",
            "\"Don't forget to tell Pedrico the head is his.\"\n",
            "\"No. i will remember.\"\n",
            "As the boy came out the door and down the worn coral beach road he was crying again.\n",
            "That afternoon there was a party of tourists at the Terrace and looking down in the\n",
            "water among the empty beer cans and dead barracudas a fisherman saw a great long white\n",
            "spine with a huge tail at the end that lifted and swung with the tide while the east wind\n",
            "blew a heavy steady sea outside the entrance to the harbour.\n",
            "\"What's that?\" she asked a waiter and pointed to the long backbone of the great fish\n",
            "that was now just garbage waiting to go out with the tide.\n",
            "\"Tiburon,\" the waiter said, \"Eshark.\" He was meaning to explain what had happened.\n",
            "\"I didn't know sharks had such handsome, beautifully formed tails.\"\n",
            "\"I didn't either,\" her male companion said.\n",
            "Up the road, in his shack, the old man was sleeping again. He was still sleeping on his\n",
            "face and the boy was standing by him watching him. The old man was dreaming of the lions.\n",
            "He held her still and steady, feeling the long length of the young body,\n",
            "and he lifted her head and kissed the wet ##ness of her eyes, and as she\n",
            "cried he could feel the rounded, firm-pointed breasts touching through the\n",
            "shirt she wore.\n",
            "I cannot kiss, she said. I do not know how.\n",
            "There is no need to kiss.\n",
            "Yes. I must kiss. I must do everything.\n",
            "There is no need to do anything. We are all right. But thou hast many\n",
            "clothes.\n",
            "What should I do?\n",
            "I will help you.\n",
            "Is it better?\n",
            "Yes. Much. Is it not good to thee?\n",
            "Yes. Much better. And I can be with thee as Pilar said?\n",
            "Yes.\n",
            "But not to a home. With thee.\n",
            "No, to a home.\n",
            "no. No. No. With thee and I will be thy woman.\n",
            "and as they lay all that before had been shielded was unshielded.\n",
            "Where there had been roughness of fabric all was smooth with a\n",
            "smoothness and a rounded pressing and a long warm coolness, cool\n",
            "outside and warm within, long and light and closely holding, closely held,\n",
            "lonely, hollow-making with contours, happy-making, young and loving and\n",
            "now all warmly smooth with a hollowing, chest-aching, tight-held\n",
            "loneliness that was such that Robert Jordan felt he could not stand it and he\n",
            "said, Hast thou no others?\n",
            "Never.\n",
            "Then suddenly, almost dead in his arms, But things were done to her.\n",
            "By whom?\n",
            "By various.\n",
            "Now she lay perfectly quietly and as though her voice were dead and\n",
            "turned her head away from him.\n",
            "Now you will not love me.\n",
            "I love you, he said.\n",
            "But something had happened to him and she knew it.\n",
            "No, she said and her voice had been dead and flat. Thou wilt not\n",
            "love me. But perhaps thou wilt take me to the home. And I will go to the\n",
            "home and I will never be thy woman nor anything.\n",
            "I love thee, Maria.\n",
            "No. It is not true, she said. Then said a last thing pitifully and hopefully:\n",
            "But I have never kissed any man.\n",
            "Then kiss me now.\n",
            "I wanted to, she said. But I know not how. Where things were done\n",
            "to me I fought and I could not see. I fought untiluntiluntil one sat\n",
            "upon my headand I bit himand then they tied my hands and held my\n",
            "arms behind my headand others did things to me.\n",
            "I love thee, Maria, he said. And no one has done anything to thee.\n",
            "Thee, they cannot touch. No one has touched thee, little rabbit.\n",
            "You believe that?\n",
            "I know it.\n",
            "how you can love me? warm again against him now.\n",
            "I can love thee more.\n",
            "I will try to kiss thee very well.\n",
            "Kiss me a little.\n",
            "I do not know how.\n",
            "Just kiss me.\n",
            "She kissed him on the cheek.\n",
            "No.\n",
            "Where do the noses go? I always wondered where the noses would\n",
            "go.\n",
            "Look, turn thy head, and then their mouths were tight together and\n",
            "she lay close pressed to him and her mouth opened a little gradually\n",
            ". then, suddenly, holding her against him, he was happier than he had\n",
            "ever been, lightly, lovingly, exultingly, innerly happy and unthinking and\n",
            "untired and unworried and only feeling a great delight and he said, My\n",
            "little rabbit. My darling. My sweet. My long lovely.\n",
            "What do you say? she said as though from a great distance away.\n",
            "My lovely one, he said.\n",
            "They were there and he felt her heart beating against his and with the side\n",
            "of his foot he stroked very lightly against the side of hers.\n",
            "Thee came barefooted, he said.\n",
            "Yes.\n",
            "Then thee knew thou wert coming to the bed.\n",
            "Yes.\n",
            "And you had no fear.\n",
            "Yes. Much. But more fear of how it would be to take my shoes off.\n",
            "And what time is it now? lo sabes?\n",
            "No. Thou hast no watch?\n",
            "Yes. But it is behind thy back.\n",
            "Take it from there.\n",
            "No.\n",
            "Then look over my shoulder.\n",
            "It was one oclock. The dial showed bright in the darkness that the robe\n",
            "made.\n",
            "my chin scratches my shoulder.\n",
            "Pardon it. I have no tools to shave.\n",
            "I like it. Is thy beard blond?\n",
            "Yes.\n",
            "but will it be long?\n",
            "Not before the bridge. Maria, listen. Dost thou?\n",
            "Do I what?\n",
            "Dost thou wish?\n",
            "Yes. Everything. Please. And if we do everything together, the other\n",
            "maybe never will have been.\n",
            "Did you think of that?\n",
            "No. I think it in myself , Pilar told me.\n",
            "She is very wise.\n",
            "And another thing, she said softly. She said for me to tell you that\n",
            "I am not sick. She knows about such things and she said to tell you that.\n",
            "She told you to tell me?\n",
            "Yes. I spoke to her and told her that I love you. I loved you when I saw\n",
            "you today and I loved you always but I never saw you before and I told\n",
            "Pilar and she said if I ever told you anything , anything, to tell you that\n",
            "I was not sick. The other thing she told me long ago. Soon after the train.\n",
            "What did she say?\n",
            "She said that nothing is done to oneself that one would not accept and\n",
            "that if I loved some one it would take it all away. I wished to die, you see.\n",
            "What she said is true.\n",
            "And now I am happy that I did not die. I am so happy that I did not die.\n",
            "And you can love me?\n",
            "Yes. I love you now.\n",
            "And I can be thy woman?\n",
            "I cannot have a woman doing what I do. But thou art my woman now.\n",
            "If once I am, then I will keep on. Am i thy woman now?\n",
            "Yes, Maria. Yes, my little rabbit.\n",
            "She held herself tight to him and her lips looked for his and then found\n",
            "his and were against them and he felt her, fresh, new and smooth and\n",
            "young and lovely with the warm, scalding coolness and unbelievable to be\n",
            "there in the robe that was as familiar as his clothes, or his shoes, or his duty\n",
            "and then she said, frightenedly, And now let us do quickly what it is we do\n",
            "so that the other is all gone.\n",
            "You know?\n",
            "Yes, she said almost fiercely. Yes. Yes. Yes.\n",
            "It was cold in the night and Robert Jordan slept heavily. Once he woke up,\n",
            "stretching, realized that the girl was there, curled face down in the robe,\n",
            "breathing lightly and regularly, and in the night, bringing his head in from\n",
            "the cold, the sky hard and sharp with stars, the air cold in his nostrils, he put\n",
            "his head under the warmth of the robe and kissed her smooth shoulder. She\n",
            "did not wake and he rolled onto his side away from her and with his head\n",
            "out of the robe in the cold again, lay awake a moment feeling the long,\n",
            "seeping luxury of his fatigue and then the smooth tactile happiness of their\n",
            "two bodies . and then, as he pushed his hands out deep as they would\n",
            "go in the robe, he slipped down steeply into sleep.\n",
            "He woke at first daylight and the girl was gone. He knew it as he woke\n",
            "and, putting out his arm, he felt the robe warm where she had been. He\n",
            "looked at the mouth of the cave where the blanket showed frost-rimmed and\n",
            "saw the thin gray smoke from the crack in the rocks that meant the kitchen\n",
            "fire was lighted.\n",
            "A man came out of the timber, a blanket worn over his head like a\n",
            "poncho. Robert Jordan saw it was Pablo and that he was smoking a\n",
            "cigarette. Hes been down corralling the horses, he thought.\n",
            "Pablo pulled open the blanket and went into the cave without looking\n",
            "toward Robert Jordan.\n",
            "Robert Jordan felt with his hand the light frost that lay on the worn,\n",
            "spotted green balloon and outer covering of the five-year-old down robe,\n",
            "then settled into it again. Bueno, he said to himself, feeling the familiar\n",
            "caress of the flannel lining as he spread his legs wide, then drew them\n",
            "together and then turned on his side so that his head would be away from\n",
            "the direction where he knew the sun would come. Qué más da, I might as\n",
            "well sleep some more.\n",
            "He slept until the sound of airplane motors woke him.\n",
            "Lying on his back, he saw them, a fascist patrol of three Fiats, tiny,\n",
            "bright, fast-moving across the mountain sky, headed in the direction from\n",
            "which Anselmo and he had come yesterday. The three passed and then\n",
            "came nine more, flying much faster in the minute, pointed formations of\n",
            "threes, threes and threes.\n",
            "Pablo and the gypsy were standing at the cave mouth, in the shadow,\n",
            "watching the sky and as Robert Jordan lay still, the sky now full of the high\n",
            "hammering roar of motors, there was a new droning roar and three more\n",
            "planes came over at less than a thousand feet above the clearing. These\n",
            "three were Heinkel one-elevens, twin-motor bombers.\n",
            "Robert Jordan, his head in the shadow of the rocks, knew they would\n",
            "not see him, and that it did not matter if they did. He knew they could\n",
            "possibly see the horses in the corral if they were looking for anything in\n",
            "these mountains. If they were not looking for anything they might still see\n",
            "them but would naturally take them for some of their own cavalry mounts.\n",
            "Then came a new and louder droning roar and three more Heinkel oneelevens \n",
            "showed coming steeply, stiffly, lower yet, crossing in rigid\n",
            "formation, their pounding roar approaching in crescendo to an absolute of\n",
            "noise and then receding as they passed the clearing.\n",
            "robert Jordan unrolled the bundle of clothing that made a pillow and\n",
            "pulled on his shirt. It was over his head and he was pulling it down when he\n",
            "heard the next planes coming and he pulled his trousers on under the robe\n",
            "and lay still as three more of the Heinkel bimotor men came over.\n",
            "Before they were gone over the shoulder of the mountain, he had buckled\n",
            "on his pistol, rolled the robe and placed it against the rocks and sat now,\n",
            "close against the rocks, tying his rope-soled shoes when the low\n",
            "droning turned to a greater clattering roar than ever before and nine more\n",
            "Heinkel light bombers came in echelons; hammering the sky apart as they\n",
            "went over.\n",
            "Robert jordan slipped along the rocks to the mouth of the cave where\n",
            "one of the brothers, pablo, the gypsy, Anselmo, Agustín and the woman\n",
            "stood in the mouth looking out.\n",
            "Have there been planes like this before? he asked.\n",
            "Never, thought Pablo. Get in. They will see thee.\n",
            "The sun had not yet hit the mouth of the cave. It was just now shining\n",
            "in the meadow by the stream . Robert Jordan knew they could not be\n",
            "seen in the dark, the morning shadow of the trees and the solid shade the\n",
            "rocks made, but he went in the cave in order not to make them nervous.\n",
            "They are many, the woman said.\n",
            "And there will be more, Robert Jordan said.\n",
            "How do you know? Pablo asked suspiciously.\n",
            "Those, just now, will have pursuit planes with them.\n",
            "Just then they heard them, the higher, whining drone, and as they passed\n",
            "at about five thousand feet, Robert Jordan counted fifteen Fiats in echelon\n",
            "of echelons like a wild-goose one of the V-shaped threes.\n",
            "In the cave entrance their faces all looked very sober and Robert Jordan\n",
            "said, i have not seen this many yet?\n",
            "Never, said Pablo.\n",
            "There are not many at Segovia?\n",
            "Never has there been, i have seen three usually. Sometimes six of the\n",
            "best. Perhaps three Junkers, the big ones with the three motors, and the\n",
            "chasers with them. Never have we seen planes like this.\n",
            "It is bad, Robert Jordan thought. This is really bad. Here is a\n",
            "concentration of planes which means something very bad. I must listen for\n",
            "them to unload. but no, they cannot have brought up the troops yet for the\n",
            "attack. Certainly not before tonight or tomorrow night, certainly not yet.\n",
            "Certainly they will not be moving anything at this time.\n",
            "He could still hear the receding drone. He looked at his watch. By now\n",
            "they should be over two lines, the first ones anyway. He pushed the knob\n",
            "that set the left hand to clicking and watched it move around. No,\n",
            "perhaps not yet. By now. Yes. Well over by now. Two hundred and fifty\n",
            "miles an hour for those one-elevens anyway. Five minutes would carry\n",
            "them there. By now theyre well in the pass with Castile all yellow\n",
            "and tawny beneath them now in the morning, the yellow crossed by white\n",
            "roads and spotted with the small villages and the shadows of the Heinkels\n",
            "moving over the land as the shadows of sharks pass over a sandy floor of\n",
            "the ocean.\n",
            "There was no bump, bump, bumping thud of bombs. His watch went\n",
            "on.\n",
            "Theyre going on to Colmenar, el Escorial, or to the flying field at\n",
            "Manzanares el Real, he thought, with the old castle above the lake with the\n",
            "ducks in the reeds and the fake airfield just beyond the real field with the\n",
            "dummy planes, not quite hidden, their props turning in the wind. Thats\n",
            "where they will be headed. They cant know about the attack, he told\n",
            "himself and something in him said, why cant they? Theyve known about\n",
            "all the others.\n",
            "Do you think they saw the horses? Pablo asked.\n",
            "Those werent looking for horses, Robert Jordan said.\n",
            "But did they see them?\n",
            "Not unless they were asked to look for them.\n",
            "Could they see them?\n",
            "Probably not, Robert Jordan said. Unless the sun were on the trees.\n",
            "it is on them very early, Pablo said miserably.\n",
            "I think they have other things to think of besides thy horses, robert\n",
            "Jordan said.\n",
            "It was eight minutes since he had pushed the lever on the stop watch\n",
            ". there was still no sound of bombing.\n",
            "What do you do with the watch? the woman asked.\n",
            "I wonder where they have gone.\n",
            "Oh, she said. At ten minutes he was looking at the watch knowing\n",
            "it would be too far away to hear, now, even allowing a minute for the sound\n",
            "to travel, and said to Anselmo, I would speak to thee.\n",
            "Anselmo came out of the cave mouth and they walked a little way from\n",
            "the entrance and stood beside a pine tree.\n",
            "Qué tal? Robert Jordan asked him. How goes it?\n",
            "All right.\n",
            "Hast thou eaten?\n",
            "No. No one has eaten.\n",
            "Eat then and take something to eat at mid-day. I want thee to go to\n",
            "watch the road. Make a map of everything that passes both up and down the\n",
            "road.\n",
            "I do not write.\n",
            "There is no need to, Robert Jordan took out two leaves from his\n",
            "notebook and with his knife cut an inch from the edge of his pencil. Take\n",
            "this and make a mark for tanks thus, he drew a slanted tank, and then a\n",
            "mark for each one and when there are four, cross the four strokes for the\n",
            "fifth.\n",
            "In this way we count also.\n",
            "Good. Make another tank, two wheels and a box, for trucks. If they\n",
            "are empty make a circle. If they are full of troops make a straight mark.\n",
            "Mark for guns. Big ones, thus. Small ones, thus. Mark for cars. Mark for\n",
            "ambulances. Thus, two wheels and a box with a gun on it. Mark for troops\n",
            "on horses by companies, like this, see? A little square . then mark beside it.\n",
            "Mark for cavalry, like this, you see? Like a horse. A box with four horses.\n",
            "That is a troop of twenty horse. You understand? a troop a mark.\n",
            "Yes. It is ingenious.\n",
            "Now, he drew two large wheels with circles around them and a short\n",
            "line for a gun barrel. These are anti-tanks. They have rubber tires. Mark\n",
            "for them. These are anti-aircraft, two wheels with the gun barrel slanted\n",
            "up. Mark for them also. Do you understand? Have you seen such guns?\n",
            "Yes, Anselmo said. Of course. It is clear.\n",
            "Take the gypsy with you that he will know from what point you will be\n",
            "watching so you may be relieved. Pick a place that is safe, not too close and\n",
            "from where you can see well and comfortably. Stay until you are relieved.\n",
            "I understand.\n",
            "Good. And that when you come back, I should know everything that\n",
            "moved upon the road. One paper is for movement up. One is for movement\n",
            "down the road.\n",
            "They walked over toward the cave.\n",
            "Send Rafael to me, Robert Jordan said and waited by the tree. He\n",
            "watched Anselmo go into the cave, the blanket falling behind him. The\n",
            "gypsy sauntered out, wiping his mouth with his hand.\n",
            "Qué tal? the gypsy said. Did you divert yourself last night?\n",
            "I slept.\n",
            "Less bad, the gypsy said and grinned. Have you a cigarette?\n",
            "Listen, Robert Jordan said and felt in his pocket for the cigarettes. I\n",
            "wish you to go with Anselmo to a place from which he will observe the\n",
            "road. There you will watch him, noting the place in order that you may\n",
            "guide me to it or guide whoever will relieve him later. You will then go to\n",
            "where you can watch the saw mill and note if there are any changes in the\n",
            "post there.\n",
            "What happened?\n",
            "How many men are there now?\n",
            "Eight. The last I knew.\n",
            "See how many are there now. See at the intervals the guard is\n",
            "relieved at that time.\n",
            "Intervals?\n",
            "How many hours the guard stays . and at what time a change is\n",
            "made.\n",
            "I have no watch.\n",
            "Take mine. He unwrapped it.\n",
            "What a watch, Rafael said admiringly. Look at what complications.\n",
            "Such a watch should be able to read and write. Look at what complications\n",
            "of numbers. Its a watch to end watches.\n",
            "Dont fool with it, Robert Jordan said. Can you tell time?\n",
            "Why not? Twelve oclock mid-day. Hunger. Twelve oclock midnight.\n",
            "Sleep. Six oclock in the morning, hunger. Six o##ock at night, drunk. With\n",
            "luck. Ten oclock at night\n",
            "Shut up, Robert Jordan said. You dont need to be a clown. I want\n",
            "you to check on the guard at the big bridge and the post on the road below\n",
            "in the same manner as the post and the guard at the saw mill and the small\n",
            "bridge.\n",
            "It is much work, the gypsy smiled. You are sure there is no one you\n",
            "would rather send than me?\n",
            "No, Rafael. It is very important. That you should do it very carefully\n",
            "and keeping out of sight with care.\n",
            "I believe I will keep out of sight, the gypsy said. Why do you tell me\n",
            "to keep out of sight? You think I want to be shot?\n",
            "take things a little seriously, Robert Jordan said. This is serious.\n",
            "Thou askest me to take things seriously? After what thou didst last\n",
            "night? When thou needest to kill a man and instead did what you did? You\n",
            "were supposed to kill one, not make one! When we have just seen the sky\n",
            "full of airplanes of a quantity to kill us back to our grandfathers and forward\n",
            "to all unborn grandsons including all cats, horses and bedbugs. Airplanes\n",
            "making a noise to curdle the milk of your mothers breasts as they pass over\n",
            "darkening the sky and roaring like lions and you ask me to take things\n",
            "seriously. I take them too seriously already.\n",
            "All right, said Robert Jordan and laughed and put his hand on the\n",
            "gypsys shoulder. Dont take them too seriously then. Now finish your\n",
            "breakfast and go.\n",
            "And go? the gypsy asked. What do i do?\n",
            "I go to see El Sordo.\n",
            "After those airplanes it is very possible that thou wilt find nobody in\n",
            "the whole mountains, the gypsy said. there must have been many people\n",
            "sweating the big drop this morning when those passed.\n",
            "Those have other work than hunting guerillas.\n",
            "Yes, the gypsy said. Then shook his head. But when they care to\n",
            "undertake that work.\n",
            "Qué va, Robert jordan said. Those are the best of the German light\n",
            "bombers. They do not send those after gypsies.\n",
            "They give me a fright, Rafael said. Of such things, yes, I am\n",
            "frightened.\n",
            "They go to bomb an airfield, Robert Jordan told him as they went into\n",
            "the cave. I am almost sure they go to that.\n",
            "What do you say? the woman of Pablo said. She poured him a bowl\n",
            "of coffee and handed him a can of condensed milk.\n",
            "There is milk? What luxury!\n",
            "There is everything, she thought. And since the planes there is much\n",
            "fear. Where did you say they went?\n",
            "Robert Jordan dripped some of the thick milk into his coffee from the\n",
            "slit cut in the can, wiped the can on the rim of the cup, and stirred the coffee\n",
            "until it was a light brown.\n",
            "They go to bomb an airfield i believe. They might go to Escorial and\n",
            "Colmenar. Perhaps all this.\n",
            "That they should go a long way and keep away from here, Pablo said.\n",
            "And why are they here now? the woman asked. What brings them\n",
            "now? Never have we seen such planes. Nor in such quantity. Do they\n",
            "prepare an attack?\n",
            "What movement was there on the road last night? Robert Jordan\n",
            "asked. The girl Maria was close to him but he did not look at her.\n",
            "You, the woman said. Fernando. You were in La Granja last night.\n",
            "What movement was there?\n",
            "Nothing, a short, open-faced man of about thirty-five with a cast in\n",
            "one eye, whom Robert Jordan had not seen before, answered. A few\n",
            "camions as usual. Some more. No movement of troops while I was there.\n",
            "You go into La paz every night? Robert Jordan asked him.\n",
            "one or another, Fernando said. Some one goes.\n",
            "They go for the news. For tobacco. For small things, the woman thought.\n",
            "We have people there?\n",
            "Yes. Why not? Those who work the power plant. Some others.\n",
            "What was the news?\n",
            "Pues nada. There was nothing. It still goes badly in the north. That is\n",
            "not news. In the north it has gone badly now since the war.\n",
            "Did you hear anything from Segovia?\n",
            "No, hombre. I did not ask.\n",
            "Do you go into Segovia?\n",
            "Sometimes, Fernando said. But there is danger. There are controls\n",
            "where they come for your papers.\n",
            "Do you know the airfield?\n",
            "No, hombre. I know where it is but I was never close to it. There, there\n",
            "is much asking for papers.\n",
            "no one spoke about these planes last night?\n",
            "In La Granja? Nobody. But they will talk about them tonight certainly.\n",
            "They talked about the broadcast of Queipo de Llano. Nothing more. Oh,\n",
            "yes. it seems that the Republic is preparing an offensive.\n",
            "That what?\n",
            "that the Republic is preparing an offensive.\n",
            "Where?\n",
            "It is not certain. Perhaps here. Perhaps for another part of the Sierra.\n",
            "Hast thou heard of it?\n",
            "They say this in La Granja?\n",
            "Yes, hombre. I had forgotten it. But there is always much talk of\n",
            "offensives.\n",
            "Where does this talk come from?\n",
            "Where? Why from different people. The officers speak in the cafés in\n",
            "Segovia and Avila and the men note it. The rumors come running. Since\n",
            "some time they speak of an offensive by the Republic in these parts.\n",
            "By the Republic or by the Fascists?\n",
            "By the Republic. If it were by the Fascists all would know of it. No,\n",
            "this is an offensive of quite some size. Some say there are two. One here\n",
            "and the other over the Alto del León near the Escorial. Have you heard\n",
            "aught of this?\n",
            "What else did you say?\n",
            "Nada, hombre. Nothing. Oh, yes. There was some talk that the\n",
            "Republicans would try to blow up the bridges, if there was to be anything\n",
            "offensive. But the bridges are guarded.\n",
            "Art thou joking? Robert Jordan said, sipping his coffee.\n",
            "No, hombre, said Fernando.\n",
            "This one doesnt joke, the woman said. good luck that he doesnt.\n",
            "Then, said Robert Jordan. Thank you for bringing the news. Did you hear\n",
            "nothing more?\n",
            "No. They talk, as always, of troops to be sent to clear out these\n",
            "mountains. There is some talk that they are on the way. That they have been\n",
            "sent already from Valladolid. But they always talk in that way. It is not to\n",
            "give much importance to.\n",
            "And thou, the woman of Pablo said to Pablo almost viciously. With\n",
            "thy talk of safety.\n",
            "Pablo looked at her reflectively and scratched his chin. Thou, he said.\n",
            "And thy bridges.\n",
            "What bridges? asked Fernando cheerfully.\n",
            "Stupid, the woman said to him. Thick head. Tonto. Take a cup\n",
            "of coffee and try to remember the news.\n",
            "Dont be angry, Pilar, Fernando said calmly and cheerfully. Neither\n",
            "will one become alarmed at rumors. I have told thee and this comrade all\n",
            "that I remember.\n",
            "You dont remember anything more? Robert Jordan asked.\n",
            "No, Fernando said with dignity. And I am fortunate to remember this\n",
            "because, since it was but rumors, I paid no attention to any of it.\n",
            "Then there may have been more?\n",
            "Yes. It is true. But I paid no attention. For a year i have heard\n",
            "nothing but rumors.\n",
            "Robert Jordan heard a quick, control-breaking sniff of laughter from the\n",
            "girl, Maria, who was standing behind him.\n",
            "tell us one more rumor, Fernandito, she said . then her shoulders\n",
            "shook again.\n",
            "If I could remember, I would not, Fernando said. It is with a\n",
            "mans dignity to listen and give importance to rumors.\n",
            "And with this we will save the Republic, the woman said.\n",
            "No. You will save it by blowing bridges, Pablo told her.\n",
            "Go, said Robert Jordan to Anselmo and Rafael. If you have eaten.\n",
            "We go now, the old man said and the two of them stood up. robert\n",
            "Jordan felt a hand on his shoulder. It was Maria. Thou shouldst eat, she\n",
            "said and let her hand rest there. Eat this so that thy stomach can support\n",
            "the rumors.\n",
            "The rumors have taken the place of the appetite.\n",
            "No. It should not be so. Eat this now before the rumors come. She\n",
            "put the bowl before him.\n",
            "Do not make a joke of me, Fernando said to her. I am thy best\n",
            "friend, Maria.\n",
            "I do not joke at all, Fernando. I only joke with him and he should eat\n",
            "or he will be hungry.\n",
            "We should all eat, Fernando said. Pilar, what passes that we are not\n",
            "hungry?\n",
            "Nothing, man, the woman of Pablo said and filled his cup with the\n",
            "meat stew. Eat. Yes, thats what you can do. Eat now.\n",
            "It is very good, Pilar, Fernando said, all dignity intact.\n",
            "Thank you, said the woman. Thank you and thank you again.\n",
            "Are you angry at me? Fernando asked.\n",
            "No. Eat. Go ahead and eat.\n",
            "I will, said Fernando. Thank you.\n",
            "Robert Jordan looked at Maria and her shoulders started shaking again\n",
            "and she looked away. Fernando ate steadily, a proud and dignified\n",
            "expression on his face, the dignity of which could not be affected even by\n",
            "the huge spoon that he was using or the slight dripping of juice from the\n",
            "stew which ran from the corners of his mouth.\n",
            "Do you like the food? the woman of Pablo asked him.\n",
            "Yes, Pilar, he said with his mouth full. It is the same as usual.\n",
            "Robert Jordan felt Marias hand on his arm and felt her fingers tighten\n",
            "with delight.\n",
            "It is for that that you like it? the woman asked Fernando.\n",
            "Yes, she said. I see. The stew; as usual. Como siempre. Things are\n",
            "bad in the north; as usual. An attack here; as usual. That troops come to\n",
            "hunt us out; as usual. You could serve as a monument to as usual.\n",
            "But the last two are only rumors, Pilar.\n",
            "Spain, the woman of Pablo said bitterly. Then turned to Robert\n",
            "Jordan. Do they have people such as this in other countries?\n",
            "There are no other countries like Spain, Robert Jordan said politely.\n",
            "You are right, Fernando said. There is no other country in the world\n",
            "like Spain.\n",
            "Hast thou ever seen any other country? the woman asked him.\n",
            "Nay, said Fernando. Nor do I wish to.\n",
            "You see? the wife of Pablo said to Robert Jordan.\n",
            "Fernandito, she said to him. Tell us of the time thee went to\n",
            "Valencia.\n",
            "i did not like Valencia.\n",
            "Why? Maria asked and pressed Robert Jordans wife again. Why did\n",
            "thee not like it?\n",
            "The people had no manners and I could not understand them. All they\n",
            "did was shout ché ##mo one another.\n",
            "Could they understand thee? Maria asked.\n",
            "They pretended not to, Fernando said.\n",
            "And what did i there?\n",
            "I left without even seeing the sea, Fernando said. I did not like the\n",
            "people.\n",
            "Oh, get out of here, you old maid, the woman of Pablo said. Get out\n",
            "of here before you make me sick. In Valencia I had the best time of my life.\n",
            "Vamos! Valencia. Dont talk to me of Valencia.\n",
            "what did thee there? Maria asked. The woman of Pablo sat down at\n",
            "the table with a bowl of coffee, a piece of bread and a bowl of the stew.\n",
            "Qué? what did we do. I was there when Finito had a fight for\n",
            "three fights at the Feria. Never have I seen so many fights. Never have I\n",
            "seen cafés so many. For hours it would be impossible to get a seat and it\n",
            "was impossible to board the tram cars. In Valencia there was danger all\n",
            "day and all night.\n",
            "But what did you do? Maria asked.\n",
            "All things, the woman said. We went to the beach and lay in the\n",
            "water and boats with sails were hauled up out of the sea by oxen. The fishermen\n",
            "driven to the water until they must swim; then harnessed to the boats, and,\n",
            "when they found their way, staggering up the sand. Ten yokes of oxen\n",
            "dragging a boat with sails out of the sea in the morning with the line of the\n",
            "small waves breaking on the sand. That is Valencia.\n",
            "But what did thee not watch oxen?\n",
            "We ate in silence on the sand. Pastries made of cooked and shredded\n",
            "fish and red and green peppers and small nuts like grains of rice. Pastries\n",
            "delicate and flaky and the fish of a richness that was incredible. Prawns\n",
            "fresh from the sea sprinkled with lime juice. They were pink and sweet and\n",
            "there were four bites to each prawn. Of those we ate many. Then we ate paella\n",
            "with fresh sea food, clams in their shells, fish, crayfish, and small eels.\n",
            "Then we ate even smaller eels alone cooked in oil and as tiny as bean\n",
            "sprouts and curled in all directions and so tender they disappeared in the\n",
            "mouth without chewing. All the time drinking a white wine, cold, light and\n",
            "good at thirty centimos the bottle. And for an end; melon. That is the home\n",
            "of the melon.\n",
            "The melon of Castile is better, Fernando said.\n",
            "Qué va, said the woman of Pablo. The melon of Castile is for self\n",
            "abuse. The melon of Valencia for eating. When I think of those melons long\n",
            "as ones arm, green like the sea and crisp and juicy to cut and crisp than\n",
            "the early morning in summer. Aye, when I think of those smallest eels, tiny,\n",
            "delicate and in mounds on the plate. Also the beer in pitchers all through the\n",
            "afternoon, the beer sweating in its coldness in pitchers the size of water\n",
            "jugs.\n",
            "And what did thee when not eating nor drinking?\n",
            "We made love in the room with the strip wood blinds hanging on the\n",
            "balcony and a breeze through the opening of the top of the door which\n",
            "turned on hinges. We made love there, the room dark in the day time from\n",
            "the hanging blinds, and from the streets there was the scent of the flower\n",
            "market and the smell of burned powder from the firecrackers of the traca\n",
            "that ran through the streets exploding each noon during the Feria. It was a\n",
            "line of fireworks that ran through all the city, the firecrackers linked\n",
            "together and the explosions running along on poles and wires of the\n",
            "tramways, exploding with great noise and a jumping from pole to pole with\n",
            "a sharpness and a cracking of explosion you would not believe.\n",
            "We made love and then sent for another pitcher of beer with the drops\n",
            "of its coldness on the glass and when the girl brought it, I took it to the\n",
            "door and I placed the coldness of the pitcher against the back of Finito as he\n",
            "lay, now, asleep, not having wakened when the beer was brought and he\n",
            "said, No, Pilar. No, woman, let me sleep. And I said, No, wake up and\n",
            "drink this to see how cold, and he drank without opening his eyes and went\n",
            "to sleep again and I lay with my back against the pillow at the foot of the bed\n",
            "and watched him sleep, brown and dark-haired and young and quiet in his\n",
            "sleep, and drank the whole pitcher, listening now to the music of a band that\n",
            "was passing. yes, she said to Pablo. Do you know aught of such things?\n",
            "We have done things together, Pablo said.\n",
            "Yes, the woman said. Why not? And thou wert more man than Finito\n",
            "in your time. But never did we go to Valencia. Never did we lie in bed\n",
            "together and hear a band pass in Valencia.\n",
            "It was impossible, Pablo told her. We have had the opportunity to go\n",
            "to Valencia. Thou knowest that if thou wilt be reasonable. But, with Finito,\n",
            "neither did thee blow up any train.\n",
            "No, said the woman. That is what is left to do. The train. Yes. Always\n",
            "the train. No one can speak against that. That remains of all the laziness,\n",
            "sloth and failure. That remains of the cowardice of this moment. There were\n",
            "many other things before too. I do not want to be here. But no one can\n",
            "speak against Valencia either. You hear me?\n",
            "I did not like it, Fernando said quietly. I did not like Valencia.\n",
            "Yet they speak of the fish as stubborn, the woman said. Clean up,\n",
            "Maria, that we may go.\n",
            "As she said this they heard the first sound of the planes returning.\n",
            "\n",
            "Список заполненных слов:\n",
            "\n",
            "*[0]* → that\n",
            "*[1]* → more\n",
            "*[2]* → man\n",
            "*[3]* → do\n",
            "*[4]* → the\n",
            "*[5]* → while\n",
            "*[6]* → jaw\n",
            "*[7]* → the\n",
            "*[8]* → the\n",
            "*[9]* → very\n",
            "*[10]* → is\n",
            "*[11]* → but\n",
            "*[12]* → anything\n",
            "*[13]* → it\n",
            "*[14]* → my\n",
            "*[15]* → sin\n",
            "*[16]* → he\n",
            "*[17]* → thought\n",
            "*[18]* → you\n",
            "*[19]* → kill\n",
            "*[20]* → \"\n",
            "*[21]* → fed\n",
            "*[22]* → sharks\n",
            "*[23]* → just\n",
            "*[24]* → boy\n",
            "*[25]* → a\n",
            "*[26]* → on\n",
            "*[27]* → head\n",
            "*[28]* → coming\n",
            "*[29]* → away\n",
            "*[30]* → hoped\n",
            "*[31]* → the\n",
            "*[32]* → even\n",
            "*[33]* → the\n",
            "*[34]* → heads\n",
            "*[35]* → is\n",
            "*[36]* → fish\n",
            "*[37]* → second\n",
            "*[38]* → of\n",
            "*[39]* → face\n",
            "*[40]* → sleep\n",
            "*[41]* → he\n",
            "*[42]* → hurt\n",
            "*[43]* → fishermen\n",
            "*[44]* → they\n",
            "*[45]* → of\n",
            "*[46]* → were\n",
            "*[47]* → yes\n",
            "*[48]* → .\n",
            "*[49]* → turned\n",
            "*[50]* → of\n",
            "*[51]* → black\n",
            "*[52]* → close\n",
            "*[53]* → been\n",
            "*[54]* → fish\n",
            "*[55]* → what\n",
            "*[56]* → let\n",
            "*[57]* → fish\n",
            "*[58]* → reached\n",
            "*[59]* → had\n",
            "*[60]* → only\n",
            "*[61]* → but\n",
            "*[62]* → .\n",
            "*[63]* → on\n",
            "*[64]* → struck\n",
            "*[65]* → fish\n",
            "*[66]* → he\n",
            "*[67]* → go\n",
            "*[68]* → the\n",
            "*[69]* → did\n",
            "*[70]* → did\n",
            "*[71]* → fish\n",
            "*[72]* → the\n",
            "*[73]* → there\n",
            "*[74]* → done\n",
            "*[75]* → of\n",
            "*[76]* → he\n",
            "*[77]* → the\n",
            "*[78]* → away\n",
            "*[79]* → he\n",
            "*[80]* → that\n",
            "*[81]* → the\n",
            "*[82]* → man\n",
            "*[83]* → day\n",
            "*[84]* → try\n",
            "*[85]* → yourself\n",
            "*[86]* → ,\n",
            "*[87]* → is\n",
            "*[88]* → that\n",
            "*[89]* → for\n",
            "*[90]* → out\n",
            "*[91]* → a\n",
            "*[92]* → fish\n",
            "*[93]* → and\n",
            "*[94]* → could\n",
            "*[95]* → the\n",
            "*[96]* → could\n",
            "*[97]* → no\n",
            "*[98]* → the\n",
            "*[99]* → fight\n",
            "*[100]* → as\n",
            "*[101]* → he\n",
            "*[102]* → than\n",
            "*[103]* → he\n",
            "*[104]* → tired\n",
            "*[105]* → old\n",
            "*[106]* → on\n",
            "*[107]* → headed\n",
            "*[108]* → side\n",
            "*[109]* → sail\n",
            "*[110]* → again\n",
            "*[111]* → boat\n",
            "*[112]* → the\n",
            "*[113]* → watched\n",
            "*[114]* → left\n",
            "*[115]* → it\n",
            "*[116]* → the\n",
            "*[117]* → man\n",
            "*[118]* → the\n",
            "*[119]* → time\n",
            "*[120]* → the\n",
            "*[121]* → back\n",
            "*[122]* → the\n",
            "*[123]* → killed\n",
            "*[124]* → had\n",
            "*[125]* → he\n",
            "*[126]* → with\n",
            "*[127]* → of\n",
            "*[128]* → far\n",
            "*[129]* → he\n",
            "*[130]* → the\n",
            "*[131]* → a\n",
            "*[132]* → to\n",
            "*[133]* → killed\n",
            "*[134]* → do\n",
            "*[135]* → your\n",
            "*[136]* → what\n",
            "*[137]* → could\n",
            "*[138]* → would\n",
            "*[139]* → do\n",
            "*[140]* → do\n",
            "*[141]* → fight\n",
            "*[142]* → told\n",
            "*[143]* → i\n",
            "*[144]* → anything\n",
            "*[145]* → and\n",
            "*[146]* → but\n",
            "*[147]* → you\n",
            "*[148]* → it\n",
            "*[149]* → it\n",
            "*[150]* → for\n",
            "*[151]* → i\n",
            "*[152]* → sleep\n",
            "*[153]* → knew\n",
            "*[154]* → of\n",
            "*[155]* → were\n",
            "*[156]* → he\n",
            "*[157]* → thought\n",
            "*[158]* → the\n",
            "*[159]* → tired\n",
            "*[160]* → night\n",
            "*[161]* → thought\n",
            "*[162]* → do\n",
            "*[163]* → fish\n",
            "*[164]* → could\n",
            "*[165]* → line\n",
            "*[166]* → they\n",
            "*[167]* → their\n",
            "*[168]* → fish\n",
            "*[169]* → line\n",
            "*[170]* → it\n",
            "*[171]* → cutting\n",
            "*[172]* → just\n",
            "*[173]* → began\n",
            "*[174]* → that\n",
            "*[175]* → fish\n",
            "*[176]* → back\n",
            "*[177]* → break\n",
            "*[178]* → felt\n",
            "*[179]* → his\n",
            "*[180]* → was\n",
            "*[181]* → old\n",
            "*[182]* → in\n",
            "*[183]* → was\n",
            "*[184]* → ,\n",
            "*[185]* → of\n",
            "*[186]* → .\n",
            "*[187]* → as\n",
            "*[188]* → could\n",
            "*[189]* → fish\n",
            "*[190]* → did\n",
            "*[191]* → the\n",
            "*[192]* → fish\n",
            "*[193]* → the\n",
            "*[194]* → could\n",
            "*[195]* → on\n",
            "*[196]* → my\n",
            "*[197]* → he\n",
            "*[198]* → he\n",
            "*[199]* → said\n",
            "*[200]* → boat\n",
            "*[201]* → and\n",
            "*[202]* → water\n",
            "*[203]* → to\n",
            "*[204]* → sail\n",
            "*[205]* → then\n",
            "*[206]* → felt\n",
            "*[207]* → moment\n",
            "*[208]* → for\n",
            "*[209]* → get\n",
            "*[210]* → mast\n",
            "*[211]* → the\n",
            "*[212]* → watched\n",
            "*[213]* → and\n",
            "*[214]* → to\n",
            "*[215]* → the\n",
            "*[216]* → hands\n",
            "*[217]* → on\n",
            "*[218]* → would\n",
            "*[219]* → come\n",
            "*[220]* → come\n",
            "*[221]* → was\n",
            "*[222]* → old\n",
            "*[223]* → to\n",
            "*[224]* → to\n",
            "*[225]* → he\n",
            "*[226]* → him\n",
            "*[227]* → tail\n",
            "*[228]* → fish\n",
            "*[229]* → any\n",
            "*[230]* → he\n",
            "*[231]* → the\n",
            "*[232]* → kill\n",
            "*[233]* → back\n",
            "*[234]* → off\n",
            "*[235]* → beat\n",
            "*[236]* → no\n",
            "*[237]* → fish\n",
            "*[238]* → fish\n",
            "*[239]* → we\n",
            "*[240]* → same\n",
            "*[241]* → of\n",
            "*[242]* → the\n",
            "*[243]* → is\n",
            "*[244]* → know\n",
            "*[245]* → one\n",
            "*[246]* → we\n",
            "*[247]* → not\n",
            "*[248]* → good\n",
            "*[249]* → in\n",
            "*[250]* → it\n",
            "*[251]* → of\n",
            "*[252]* → how\n",
            "*[253]* → breaking\n",
            "*[254]* → can\n",
            "*[255]* → learn\n",
            "*[256]* → said\n",
            "*[257]* → i\n",
            "*[258]* → came\n",
            "*[259]* → beach\n",
            "*[260]* → fisherman\n",
            "*[261]* → a\n",
            "*[262]* → to\n",
            "*[263]* → and\n",
            "*[264]* → standing\n",
            "*[265]* → of\n",
            "*[266]* → steady\n",
            "*[267]* → lifted\n",
            "*[268]* → ##ness\n",
            "*[269]* → he\n",
            "*[270]* → she\n",
            "*[271]* → do\n",
            "*[272]* → it\n",
            "*[273]* → good\n",
            "*[274]* → be\n",
            "*[275]* → to\n",
            "*[276]* → no\n",
            "*[277]* → and\n",
            "*[278]* → a\n",
            "*[279]* → and\n",
            "*[280]* → such\n",
            "*[281]* → no\n",
            "*[282]* → almost\n",
            "*[283]* → her\n",
            "*[284]* → voice\n",
            "*[285]* → him\n",
            "*[286]* → been\n",
            "*[287]* → not\n",
            "*[288]* → said\n",
            "*[289]* → how\n",
            "*[290]* → and\n",
            "*[291]* → fought\n",
            "*[292]* → hands\n",
            "*[293]* → thee\n",
            "*[294]* → how\n",
            "*[295]* → know\n",
            "*[296]* → on\n",
            "*[297]* → to\n",
            "*[298]* → .\n",
            "*[299]* → were\n",
            "*[300]* → time\n",
            "*[301]* → no\n",
            "*[302]* → is\n",
            "*[303]* → over\n",
            "*[304]* → my\n",
            "*[305]* → but\n",
            "*[306]* → ,\n",
            "*[307]* → she\n",
            "*[308]* → she\n",
            "*[309]* → me\n",
            "*[310]* → she\n",
            "*[311]* → ,\n",
            "*[312]* → would\n",
            "*[313]* → take\n",
            "*[314]* → that\n",
            "*[315]* → me\n",
            "*[316]* → now\n",
            "*[317]* → art\n",
            "*[318]* → i\n",
            "*[319]* → to\n",
            "*[320]* → his\n",
            "*[321]* → what\n",
            "*[322]* → know\n",
            "*[323]* → up\n",
            "*[324]* → face\n",
            "*[325]* → night\n",
            "*[326]* → the\n",
            "*[327]* → his\n",
            "*[328]* → and\n",
            "*[329]* → .\n",
            "*[330]* → hands\n",
            "*[331]* → the\n",
            "*[332]* → the\n",
            "*[333]* → his\n",
            "*[334]* → and\n",
            "*[335]* → himself\n",
            "*[336]* → then\n",
            "*[337]* → his\n",
            "*[338]* → would\n",
            "*[339]* → a\n",
            "*[340]* → the\n",
            "*[341]* → faster\n",
            "*[342]* → in\n",
            "*[343]* → did\n",
            "*[344]* → see\n",
            "*[345]* → and\n",
            "*[346]* → robert\n",
            "*[347]* → a\n",
            "*[348]* → heard\n",
            "*[349]* → men\n",
            "*[350]* → he\n",
            "*[351]* → low\n",
            "*[352]* → before\n",
            "*[353]* → jordan\n",
            "*[354]* → pablo\n",
            "*[355]* → like\n",
            "*[356]* → thought\n",
            "*[357]* → yet\n",
            "*[358]* → in\n",
            "*[359]* → .\n",
            "*[360]* → the\n",
            "*[361]* → one\n",
            "*[362]* → i\n",
            "*[363]* → yet\n",
            "*[364]* → i\n",
            "*[365]* → best\n",
            "*[366]* → and\n",
            "*[367]* → very\n",
            "*[368]* → but\n",
            "*[369]* → for\n",
            "*[370]* → time\n",
            "*[371]* → two\n",
            "*[372]* → left\n",
            "*[373]* → an\n",
            "*[374]* → in\n",
            "*[375]* → of\n",
            "*[376]* → went\n",
            "*[377]* → el\n",
            "*[378]* → the\n",
            "*[379]* → beyond\n",
            "*[380]* → will\n",
            "*[381]* → told\n",
            "*[382]* → it\n",
            "*[383]* → think\n",
            "*[384]* → robert\n",
            "*[385]* → .\n",
            "*[386]* → the\n",
            "*[387]* → wonder\n",
            "*[388]* → was\n",
            "*[389]* → eaten\n",
            "*[390]* → thee\n",
            "*[391]* → map\n",
            "*[392]* → edge\n",
            "*[393]* → the\n",
            "*[394]* → tank\n",
            "*[395]* → they\n",
            "*[396]* → gun\n",
            "*[397]* → horses\n",
            "*[398]* → .\n",
            "*[399]* → horses\n",
            "*[400]* → a\n",
            "*[401]* → will\n",
            "*[402]* → that\n",
            "*[403]* → the\n",
            "*[404]* → the\n",
            "*[405]* → cave\n",
            "*[406]* → gypsy\n",
            "*[407]* → from\n",
            "*[408]* → watch\n",
            "*[409]* → will\n",
            "*[410]* → watch\n",
            "*[411]* → there\n",
            "*[412]* → happened\n",
            "*[413]* → the\n",
            "*[414]* → time\n",
            "*[415]* → .\n",
            "*[416]* → be\n",
            "*[417]* → at\n",
            "*[418]* → clock\n",
            "*[419]* → ##ock\n",
            "*[420]* → sure\n",
            "*[421]* → it\n",
            "*[422]* → with\n",
            "*[423]* → take\n",
            "*[424]* → take\n",
            "*[425]* → horses\n",
            "*[426]* → of\n",
            "*[427]* → seriously\n",
            "*[428]* → seriously\n",
            "*[429]* → go\n",
            "*[430]* → i\n",
            "*[431]* → there\n",
            "*[432]* → morning\n",
            "*[433]* → jordan\n",
            "*[434]* → fright\n",
            "*[435]* → to\n",
            "*[436]* → said\n",
            "*[437]* → thought\n",
            "*[438]* → from\n",
            "*[439]* → until\n",
            "*[440]* → i\n",
            "*[441]* → this\n",
            "*[442]* → now\n",
            "*[443]* → such\n",
            "*[444]* → was\n",
            "*[445]* → a\n",
            "*[446]* → more\n",
            "*[447]* → paz\n",
            "*[448]* → one\n",
            "*[449]* → thought\n",
            "*[450]* → work\n",
            "*[451]* → war\n",
            "*[452]* → come\n",
            "*[453]* → no\n",
            "*[454]* → it\n",
            "*[455]* → that\n",
            "*[456]* → of\n",
            "*[457]* → is\n",
            "*[458]* → men\n",
            "*[459]* → of\n",
            "*[460]* → there\n",
            "*[461]* → the\n",
            "*[462]* → say\n",
            "*[463]* → that\n",
            "*[464]* → anything\n",
            "*[465]* → good\n",
            "*[466]* → bringing\n",
            "*[467]* → be\n",
            "*[468]* → that\n",
            "*[469]* → been\n",
            "*[470]* → much\n",
            "*[471]* → the\n",
            "*[472]* → a\n",
            "*[473]* → the\n",
            "*[474]* → will\n",
            "*[475]* → any\n",
            "*[476]* → true\n",
            "*[477]* → i\n",
            "*[478]* → tell\n",
            "*[479]* → .\n",
            "*[480]* → with\n",
            "*[481]* → robert\n",
            "*[482]* → shoulder\n",
            "*[483]* → this\n",
            "*[484]* → the\n",
            "*[485]* → the\n",
            "*[486]* → the\n",
            "*[487]* → best\n",
            "*[488]* → all\n",
            "*[489]* → hungry\n",
            "*[490]* → cup\n",
            "*[491]* → do\n",
            "*[492]* → you\n",
            "*[493]* → ate\n",
            "*[494]* → the\n",
            "*[495]* → hand\n",
            "*[496]* → attack\n",
            "*[497]* → world\n",
            "*[498]* → wife\n",
            "*[499]* → she\n",
            "*[500]* → i\n",
            "*[501]* → wife\n",
            "*[502]* → not\n",
            "*[503]* → ##mo\n",
            "*[504]* → not\n",
            "*[505]* → i\n",
            "*[506]* → said\n",
            "*[507]* → woman\n",
            "*[508]* → what\n",
            "*[509]* → a\n",
            "*[510]* → do\n",
            "*[511]* → fight\n",
            "*[512]* → fights\n",
            "*[513]* → many\n",
            "*[514]* → was\n",
            "*[515]* → danger\n",
            "*[516]* → fishermen\n",
            "*[517]* → way\n",
            "*[518]* → boat\n",
            "*[519]* → sand\n",
            "*[520]* → not\n",
            "*[521]* → silence\n",
            "*[522]* → each\n",
            "*[523]* → fish\n",
            "*[524]* → we\n",
            "*[525]* → the\n",
            "*[526]* → crisp\n",
            "*[527]* → think\n",
            "*[528]* → in\n",
            "*[529]* → on\n",
            "*[530]* → the\n",
            "*[531]* → of\n",
            "*[532]* → smell\n",
            "*[533]* → was\n",
            "*[534]* → with\n",
            "*[535]* → would\n",
            "*[536]* → to\n",
            "*[537]* → of\n",
            "*[538]* → the\n",
            "*[539]* → said\n",
            "*[540]* → and\n",
            "*[541]* → the\n",
            "*[542]* → the\n",
            "*[543]* → in\n",
            "*[544]* → to\n",
            "*[545]* → yes\n",
            "*[546]* → did\n",
            "*[547]* → the\n",
            "*[548]* → do\n",
            "*[549]* → here\n",
            "*[550]* → fish\n",
            "\n",
            "Только заполненные слова:\n",
            "\n",
            "that\n",
            "more\n",
            "man\n",
            "do\n",
            "the\n",
            "while\n",
            "jaw\n",
            "the\n",
            "the\n",
            "very\n",
            "is\n",
            "but\n",
            "anything\n",
            "it\n",
            "my\n",
            "sin\n",
            "he\n",
            "thought\n",
            "you\n",
            "kill\n",
            "\"\n",
            "fed\n",
            "sharks\n",
            "just\n",
            "boy\n",
            "a\n",
            "on\n",
            "head\n",
            "coming\n",
            "away\n",
            "hoped\n",
            "the\n",
            "even\n",
            "the\n",
            "heads\n",
            "is\n",
            "fish\n",
            "second\n",
            "of\n",
            "face\n",
            "sleep\n",
            "he\n",
            "hurt\n",
            "fishermen\n",
            "they\n",
            "of\n",
            "were\n",
            "yes\n",
            ".\n",
            "turned\n",
            "of\n",
            "black\n",
            "close\n",
            "been\n",
            "fish\n",
            "what\n",
            "let\n",
            "fish\n",
            "reached\n",
            "had\n",
            "only\n",
            "but\n",
            ".\n",
            "on\n",
            "struck\n",
            "fish\n",
            "he\n",
            "go\n",
            "the\n",
            "did\n",
            "did\n",
            "fish\n",
            "the\n",
            "there\n",
            "done\n",
            "of\n",
            "he\n",
            "the\n",
            "away\n",
            "he\n",
            "that\n",
            "the\n",
            "man\n",
            "day\n",
            "try\n",
            "yourself\n",
            ",\n",
            "is\n",
            "that\n",
            "for\n",
            "out\n",
            "a\n",
            "fish\n",
            "and\n",
            "could\n",
            "the\n",
            "could\n",
            "no\n",
            "the\n",
            "fight\n",
            "as\n",
            "he\n",
            "than\n",
            "he\n",
            "tired\n",
            "old\n",
            "on\n",
            "headed\n",
            "side\n",
            "sail\n",
            "again\n",
            "boat\n",
            "the\n",
            "watched\n",
            "left\n",
            "it\n",
            "the\n",
            "man\n",
            "the\n",
            "time\n",
            "the\n",
            "back\n",
            "the\n",
            "killed\n",
            "had\n",
            "he\n",
            "with\n",
            "of\n",
            "far\n",
            "he\n",
            "the\n",
            "a\n",
            "to\n",
            "killed\n",
            "do\n",
            "your\n",
            "what\n",
            "could\n",
            "would\n",
            "do\n",
            "do\n",
            "fight\n",
            "told\n",
            "i\n",
            "anything\n",
            "and\n",
            "but\n",
            "you\n",
            "it\n",
            "it\n",
            "for\n",
            "i\n",
            "sleep\n",
            "knew\n",
            "of\n",
            "were\n",
            "he\n",
            "thought\n",
            "the\n",
            "tired\n",
            "night\n",
            "thought\n",
            "do\n",
            "fish\n",
            "could\n",
            "line\n",
            "they\n",
            "their\n",
            "fish\n",
            "line\n",
            "it\n",
            "cutting\n",
            "just\n",
            "began\n",
            "that\n",
            "fish\n",
            "back\n",
            "break\n",
            "felt\n",
            "his\n",
            "was\n",
            "old\n",
            "in\n",
            "was\n",
            ",\n",
            "of\n",
            ".\n",
            "as\n",
            "could\n",
            "fish\n",
            "did\n",
            "the\n",
            "fish\n",
            "the\n",
            "could\n",
            "on\n",
            "my\n",
            "he\n",
            "he\n",
            "said\n",
            "boat\n",
            "and\n",
            "water\n",
            "to\n",
            "sail\n",
            "then\n",
            "felt\n",
            "moment\n",
            "for\n",
            "get\n",
            "mast\n",
            "the\n",
            "watched\n",
            "and\n",
            "to\n",
            "the\n",
            "hands\n",
            "on\n",
            "would\n",
            "come\n",
            "come\n",
            "was\n",
            "old\n",
            "to\n",
            "to\n",
            "he\n",
            "him\n",
            "tail\n",
            "fish\n",
            "any\n",
            "he\n",
            "the\n",
            "kill\n",
            "back\n",
            "off\n",
            "beat\n",
            "no\n",
            "fish\n",
            "fish\n",
            "we\n",
            "same\n",
            "of\n",
            "the\n",
            "is\n",
            "know\n",
            "one\n",
            "we\n",
            "not\n",
            "good\n",
            "in\n",
            "it\n",
            "of\n",
            "how\n",
            "breaking\n",
            "can\n",
            "learn\n",
            "said\n",
            "i\n",
            "came\n",
            "beach\n",
            "fisherman\n",
            "a\n",
            "to\n",
            "and\n",
            "standing\n",
            "of\n",
            "steady\n",
            "lifted\n",
            "##ness\n",
            "he\n",
            "she\n",
            "do\n",
            "it\n",
            "good\n",
            "be\n",
            "to\n",
            "no\n",
            "and\n",
            "a\n",
            "and\n",
            "such\n",
            "no\n",
            "almost\n",
            "her\n",
            "voice\n",
            "him\n",
            "been\n",
            "not\n",
            "said\n",
            "how\n",
            "and\n",
            "fought\n",
            "hands\n",
            "thee\n",
            "how\n",
            "know\n",
            "on\n",
            "to\n",
            ".\n",
            "were\n",
            "time\n",
            "no\n",
            "is\n",
            "over\n",
            "my\n",
            "but\n",
            ",\n",
            "she\n",
            "she\n",
            "me\n",
            "she\n",
            ",\n",
            "would\n",
            "take\n",
            "that\n",
            "me\n",
            "now\n",
            "art\n",
            "i\n",
            "to\n",
            "his\n",
            "what\n",
            "know\n",
            "up\n",
            "face\n",
            "night\n",
            "the\n",
            "his\n",
            "and\n",
            ".\n",
            "hands\n",
            "the\n",
            "the\n",
            "his\n",
            "and\n",
            "himself\n",
            "then\n",
            "his\n",
            "would\n",
            "a\n",
            "the\n",
            "faster\n",
            "in\n",
            "did\n",
            "see\n",
            "and\n",
            "robert\n",
            "a\n",
            "heard\n",
            "men\n",
            "he\n",
            "low\n",
            "before\n",
            "jordan\n",
            "pablo\n",
            "like\n",
            "thought\n",
            "yet\n",
            "in\n",
            ".\n",
            "the\n",
            "one\n",
            "i\n",
            "yet\n",
            "i\n",
            "best\n",
            "and\n",
            "very\n",
            "but\n",
            "for\n",
            "time\n",
            "two\n",
            "left\n",
            "an\n",
            "in\n",
            "of\n",
            "went\n",
            "el\n",
            "the\n",
            "beyond\n",
            "will\n",
            "told\n",
            "it\n",
            "think\n",
            "robert\n",
            ".\n",
            "the\n",
            "wonder\n",
            "was\n",
            "eaten\n",
            "thee\n",
            "map\n",
            "edge\n",
            "the\n",
            "tank\n",
            "they\n",
            "gun\n",
            "horses\n",
            ".\n",
            "horses\n",
            "a\n",
            "will\n",
            "that\n",
            "the\n",
            "the\n",
            "cave\n",
            "gypsy\n",
            "from\n",
            "watch\n",
            "will\n",
            "watch\n",
            "there\n",
            "happened\n",
            "the\n",
            "time\n",
            ".\n",
            "be\n",
            "at\n",
            "clock\n",
            "##ock\n",
            "sure\n",
            "it\n",
            "with\n",
            "take\n",
            "take\n",
            "horses\n",
            "of\n",
            "seriously\n",
            "seriously\n",
            "go\n",
            "i\n",
            "there\n",
            "morning\n",
            "jordan\n",
            "fright\n",
            "to\n",
            "said\n",
            "thought\n",
            "from\n",
            "until\n",
            "i\n",
            "this\n",
            "now\n",
            "such\n",
            "was\n",
            "a\n",
            "more\n",
            "paz\n",
            "one\n",
            "thought\n",
            "work\n",
            "war\n",
            "come\n",
            "no\n",
            "it\n",
            "that\n",
            "of\n",
            "is\n",
            "men\n",
            "of\n",
            "there\n",
            "the\n",
            "say\n",
            "that\n",
            "anything\n",
            "good\n",
            "bringing\n",
            "be\n",
            "that\n",
            "been\n",
            "much\n",
            "the\n",
            "a\n",
            "the\n",
            "will\n",
            "any\n",
            "true\n",
            "i\n",
            "tell\n",
            ".\n",
            "with\n",
            "robert\n",
            "shoulder\n",
            "this\n",
            "the\n",
            "the\n",
            "the\n",
            "best\n",
            "all\n",
            "hungry\n",
            "cup\n",
            "do\n",
            "you\n",
            "ate\n",
            "the\n",
            "hand\n",
            "attack\n",
            "world\n",
            "wife\n",
            "she\n",
            "i\n",
            "wife\n",
            "not\n",
            "##mo\n",
            "not\n",
            "i\n",
            "said\n",
            "woman\n",
            "what\n",
            "a\n",
            "do\n",
            "fight\n",
            "fights\n",
            "many\n",
            "was\n",
            "danger\n",
            "fishermen\n",
            "way\n",
            "boat\n",
            "sand\n",
            "not\n",
            "silence\n",
            "each\n",
            "fish\n",
            "we\n",
            "the\n",
            "crisp\n",
            "think\n",
            "in\n",
            "on\n",
            "the\n",
            "of\n",
            "smell\n",
            "was\n",
            "with\n",
            "would\n",
            "to\n",
            "of\n",
            "the\n",
            "said\n",
            "and\n",
            "the\n",
            "the\n",
            "in\n",
            "to\n",
            "yes\n",
            "did\n",
            "the\n",
            "do\n",
            "here\n",
            "fish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# НОРМ КОД\n"
      ],
      "metadata": {
        "id": "MBkzXnHjZP7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForMaskedLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    pipeline\n",
        ")\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "hYJJhIS9bjYS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем датасет из текстового файла\n",
        "dataset = load_dataset(\"text\", data_files={\"train\": \"train.txt\"}, split=\"train\")\n",
        "\n",
        "# Загружаем предобученный токенизатор BERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Функция для токенизации и разбиения длинных текстов на части\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "        stride=128,  # Перекрытие между частями текста\n",
        "        return_overflowing_tokens=True\n",
        "    )\n",
        "\n",
        "# Применяем токенизацию к датасету\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "# Загружаем модель для masked language modeling\n",
        "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Создаем data collator для случайного маскирования токенов (15% токенов)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
        "\n",
        "# Определяем аргументы обучения\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_mlm\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,  # Уменьшаем размер батча для экономии памяти\n",
        "    save_steps=10000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        "    logging_steps=500,\n",
        ")\n",
        "\n",
        "# Создаем объект Trainer для обучения модели\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Запускаем процесс обучения\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "13dff50837764e13a35378941477d47b",
            "0999b9c05d054775bca14d45f6aeaa01",
            "4f53b80edb9f42c495e54053a500148b",
            "e8ae618e525544d09fbb8a97e3749f57",
            "758aeb283bb14981bf09bccb8564a12b",
            "725cc062d3414810833b02e6d27923aa",
            "3c96b1da90d3481e800ee92af1907dbc",
            "435880003ce2494c92da7b27941efffa",
            "d077b5697e844a6da342b5ed9802c815",
            "d2fe2b257aba4e2c9c5ac2448ed335a0",
            "2ee2c7120d764660ad91dfd1abf96abe"
          ]
        },
        "id": "WsVJAh_2bm7t",
        "outputId": "4071db2d-5fb8-4953-f273-8db33407f73c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3711 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13dff50837764e13a35378941477d47b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='464' max='464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [464/464 06:36, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=464, training_loss=2.6174779431573274, metrics={'train_runtime': 397.3741, 'train_samples_per_second': 9.339, 'train_steps_per_second': 1.168, 'total_flos': 976753060300800.0, 'train_loss': 2.6174779431573274, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохраняем модель и токенизатор\n",
        "trainer.save_model(\"./bert_mlm\")\n",
        "tokenizer.save_pretrained(\"./bert_mlm\")\n",
        "\n",
        "# Создаем pipeline для задачи fill-mask\n",
        "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAME3roBbpwy",
        "outputId": "401772cc-a170-41f6-c03b-295e069da786"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем текст для валидации\n",
        "with open(\"test.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_text = f.read()\n",
        "\n",
        "# Регулярное выражение для поиска шаблона, например: *[0]*, *[1]* и т.д.\n",
        "pattern = r\"\\*\\[\\d+\\]\\*\"\n",
        "\n",
        "# Для хранения заполненных слов\n",
        "filled_words = []\n",
        "\n",
        "# Пока в тексте встречается хотя бы один шаблон\n",
        "while re.search(pattern, test_text):\n",
        "    # Находим первое вхождение шаблона\n",
        "    placeholder = re.search(pattern, test_text).group(0)\n",
        "\n",
        "    # Заменяем первое найденное вхождение на токен [MASK]\n",
        "    test_text = re.sub(pattern, tokenizer.mask_token, test_text, count=1)\n",
        "\n",
        "    # Проверяем длину текста и разбиваем на части, если необходимо\n",
        "    if len(tokenizer.encode(test_text)) > 512:\n",
        "        # Находим позицию маски\n",
        "        mask_pos = test_text.find(tokenizer.mask_token)\n",
        "\n",
        "        # Вырезаем кусок текста вокруг маски, не превышающий 512 токенов\n",
        "        start = max(0, mask_pos - 200)\n",
        "        end = min(len(test_text), mask_pos + 200)\n",
        "        text_chunk = test_text[start:end]\n",
        "\n",
        "        # Получаем предсказание для токена [MASK] в обрезанном тексте\n",
        "        predictions = fill_mask(text_chunk)\n",
        "        predicted_token = predictions[0]['token_str'].strip()\n",
        "\n",
        "        # Сохраняем предсказанное слово и его позицию в шаблоне\n",
        "        filled_words.append((placeholder, predicted_token))\n",
        "\n",
        "        # Заменяем маску в оригинальном тексте\n",
        "        test_text = test_text[:mask_pos] + predicted_token + test_text[mask_pos + len(tokenizer.mask_token):]\n",
        "    else:\n",
        "        # Получаем предсказание для токена [MASK]\n",
        "        predictions = fill_mask(test_text)\n",
        "        predicted_token = predictions[0]['token_str'].strip()\n",
        "\n",
        "        # Сохраняем предсказанное слово и его позицию в шаблоне\n",
        "        filled_words.append((placeholder, predicted_token))\n",
        "\n",
        "        # Заменяем первый найденный [MASK] на предсказанное слово\n",
        "        test_text = test_text.replace(tokenizer.mask_token, predicted_token, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lM_mjukbtL6",
        "outputId": "af82832a-3ecf-44f0-9259-6bcd0223be6c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (15707 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Вывод результатов\n",
        "print(\"Заполненный текст:\\n\")\n",
        "print(test_text)\n",
        "\n",
        "print(\"\\nСписок заполненных слов:\\n\")\n",
        "for placeholder, word in filled_words:\n",
        "    print(f\"{placeholder} → {word}\")\n",
        "\n",
        "print(\"\\nТолько заполненные слова:\\n\")\n",
        "df = pd.DataFrame()\n",
        "lst = []\n",
        "for _, word in filled_words:\n",
        "    lst.append(word)"
      ],
      "metadata": {
        "id": "D0CB2Vz0bgno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst2 = []\n",
        "for i in range(len(lst)):\n",
        "  lst2.append(i)"
      ],
      "metadata": {
        "id": "wodtHKHAeXVf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['id'] = lst2\n",
        "df['target'] = lst"
      ],
      "metadata": {
        "id": "up8ffJnHejj7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Sg5R4-nAeqge",
        "outputId": "138ba369-9763-48e9-ee8a-f12eefba333b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id target\n",
              "0      0   that\n",
              "1      1   more\n",
              "2      2    man\n",
              "3      3     do\n",
              "4      4    the\n",
              "..   ...    ...\n",
              "546  546    did\n",
              "547  547    the\n",
              "548  548     do\n",
              "549  549   here\n",
              "550  550   fish\n",
              "\n",
              "[551 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb7cb617-933b-4ff2-b11c-0de2bf737856\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>more</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>do</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>546</td>\n",
              "      <td>did</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>547</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>548</td>\n",
              "      <td>do</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>549</td>\n",
              "      <td>here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>550</td>\n",
              "      <td>fish</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>551 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb7cb617-933b-4ff2-b11c-0de2bf737856')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb7cb617-933b-4ff2-b11c-0de2bf737856 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb7cb617-933b-4ff2-b11c-0de2bf737856');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6f235b7-b9c0-4129-b75b-caed6b7cc84e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6f235b7-b9c0-4129-b75b-caed6b7cc84e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6f235b7-b9c0-4129-b75b-caed6b7cc84e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 551,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159,\n        \"min\": 0,\n        \"max\": 550,\n        \"num_unique_values\": 551,\n        \"samples\": [\n          546,\n          81,\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 212,\n        \"samples\": [\n          \"heads\",\n          \"happened\",\n          \"art\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}