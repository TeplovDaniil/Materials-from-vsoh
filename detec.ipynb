{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú–æ–¥—É–ª—å –ë."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image, ImageFont\n",
    "\n",
    "# –¥–ª—è –º–æ–¥–µ–ª–∏ yolo \n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–∞–º–æ–ø–∏—Å–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from IPython.display import Image\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ –¥–≤–µ –≤—ã–±–æ—Ä–∫–∏:\n",
    "\n",
    "1. –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é(–ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)\n",
    "2. –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é(–ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏)\n",
    "\n",
    "–î–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏. –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, –∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è ‚Äî –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –µ—ë —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –æ–±–æ–±—â–∞—Ç—å –Ω–∞ –Ω–æ–≤—ã–µ, –Ω–µ–∏–∑–≤–µ–¥–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –æ—à–∏–±–∫—É –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏, –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "–ë—ã–ª –≤—ã–±—Ä–∞–Ω —Ä–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ –≤ 30 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤, –ø–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –±–æ–ª—å—à–æ–π –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö –∏ –∏—Ö —Å –∑–∞–ø–∞—Å–æ–º —Ö–≤–∞—Ç–∏—Ç –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É –º–æ–¥–µ–ª–∏. –¢–∞–∫–∂–µ –≤–∞–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏, —É –Ω–∞—Å –≤ –¥–∞–Ω–Ω—ã—Ö –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–æ–≤. –ò—Å—Ö–æ–¥—è –∏–∑ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤—ã–±—Ä–∞–Ω —Ä–∞–∑–º–µ—Ä –≤ 30 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤, –∫–∞–∫ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Ä–∞–∑–±–∏–µ–Ω–∏—è, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–æ–¥ –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°–æ–∑–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: 6727 —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö, 2883 –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.\n"
     ]
    }
   ],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "def split_dataset(images_dir, labels_dir, output_dir, train_ratio=0.7):\n",
    "    # –ü—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    train_images_dir = os.path.join(output_dir, \"train/images\")\n",
    "    train_labels_dir = os.path.join(output_dir, \"train/labels\")\n",
    "    val_images_dir = os.path.join(output_dir, \"val/images\")\n",
    "    val_labels_dir = os.path.join(output_dir, \"val/labels\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç\n",
    "    for folder in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir]:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è 70/30\n",
    "    split_idx = int(train_ratio * len(image_files))\n",
    "    train_files = image_files[:split_idx]\n",
    "    val_files = image_files[split_idx:]\n",
    "    \n",
    "    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "    def move_files(file_list, dst_images, dst_labels):\n",
    "        for file in file_list:\n",
    "            # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "            shutil.copy2(os.path.join(images_dir, file), os.path.join(dst_images, file))\n",
    "            \n",
    "            # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "            label_file = os.path.splitext(file)[0] + \".txt\"\n",
    "            src_label_path = os.path.join(labels_dir, label_file)\n",
    "            dst_label_path = os.path.join(dst_labels, label_file)\n",
    "            \n",
    "            if os.path.exists(src_label_path):\n",
    "                shutil.copy2(src_label_path, dst_label_path)\n",
    "    \n",
    "    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã\n",
    "    move_files(train_files, train_images_dir, train_labels_dir)\n",
    "    move_files(val_files, val_images_dir, val_labels_dir)\n",
    "    \n",
    "    print(f\"–†–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {len(train_files)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö, {len(val_files)} –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–¥–∞—Ç—å –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
    "images_path = \"images2\"\n",
    "labels_path = \"labels_bbox\"\n",
    "output_path = \"data\"\n",
    "\n",
    "# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞–∑–±–∏–µ–Ω–∏–µ\n",
    "split_dataset(images_path, labels_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ò—Ç–æ–≥:**\n",
    "\n",
    "–î–∞—Ç–∞—Å–µ—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã–±–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –¥–≤–∞ –ø–æ–¥—Ö–æ–¥–∞:\n",
    "\n",
    "1. –ë–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. \n",
    "2. –° –¥–æ–æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–í—ã–±–µ—Ä–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –æ–±–æ–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤.\n",
    "\n",
    "**–ë–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏**\n",
    "\n",
    "–°–∏–∞–º—Å–∫–∞—è —Å–µ—Ç—å –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–¥–∞—á–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –æ–±—É—á–µ–Ω–∞ –≤—ã—è–≤–ª—è—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏–ª–∏ —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏. –í –≤–∞—à–µ–º —Å–ª—É—á–∞–µ, –∫–æ–≥–¥–∞ –Ω–æ–≤—ã–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö, –∑–∞–¥–∞—á–∞ —Å–≤–æ–¥–∏—Ç—Å—è –∫ —Ç–æ–º—É, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏—Ç—å –Ω–æ–≤—É—é —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é —Å —É–∂–µ –∏–º–µ—é—â–∏–º–∏—Å—è –≤ –±–∞–∑–µ. –°–∏–∞–º—Å–∫–∞—è —Å–µ—Ç—å —Ä–µ—à–∞–µ—Ç —ç—Ç—É –∑–∞–¥–∞—á—É, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—è –¥–≤–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö –ø—É—Ç–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç—Ç–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –∏–ª–∏ –µ–≤–∫–ª–∏–¥–æ–≤–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è). –¢–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ–π –º–æ–¥–µ–ª–∏, –∏ —ç—Ç–æ —É–¥–æ–±–Ω–æ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã, –≥–¥–µ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –Ω–æ–≤—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.\n",
    "\n",
    "**–° –¥–æ–æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏**\n",
    "\n",
    "YOLO (You Only Look Once) ‚Äî —ç—Ç–æ –æ–¥–Ω–∞ –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä–∞—è —Å–ø–æ—Å–æ–±–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞—Ç—å –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –î–ª—è –∑–∞–¥–∞—á–∏ —Å –¥–æ–æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª—å YOLO —è–≤–ª—è–µ—Ç—Å—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ª–∏—Ü –∏–ª–∏ –¥—Ä—É–≥–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é fine-tuning. –í –ø—Ä–æ—Ü–µ—Å—Å–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º, —É–ª—É—á—à–∞—è —Å–≤–æ—é —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–µ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤. –ë–ª–∞–≥–æ–¥–∞—Ä—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è YOLO –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –º–æ–¥–µ–ª–∏, –æ–Ω–∞ –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–¥–∞—á–∏, –≥–¥–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –≤ –æ–±—É—á–∞—é—â–∏–π –Ω–∞–±–æ—Ä –∏ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö. –≠—Ç–æ —Ç–∞–∫–∂–µ –¥–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ —É–ª—É—á—à–∞—Ç—å —Å–≤–æ–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Ç–µ—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏, –Ω–µ —Ç—Ä–µ–±—É—è –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è —Å –Ω—É–ª—è.\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏–¥–µ–∞–ª—å–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –∑–∞–¥–∞—á–∏: —Å–∏–∞–º—Å–∫–∞—è —Å–µ—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –±—ã—Å—Ç—Ä—ã–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è, –∞ YOLO –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–∏–Ω–∞–º–∏—á–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ YOLO –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°–æ–∑–¥–∞–Ω–∏–µ data.yaml**\n",
    "\n",
    "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–∞—Ç–∞—Å–µ—Ç–µ, –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ —Å –ø–æ–º–æ—â—å—é Yolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–∏\n",
    "file_path = 'labels.txt'\n",
    "\n",
    "# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤\n",
    "labels = []\n",
    "\n",
    "# –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        image, label = line.split()\n",
    "        labels.append(int(label))\n",
    "\n",
    "# –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –∏ –∏—Ö —á–∞—Å—Ç–æ—Ç\n",
    "labels_list = list(label_counts.keys())\n",
    "counts_list = list(label_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list.append(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = sorted(set(labels_list))  # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–ª–∞—Å—Å—ã\n",
    "mapping = {old_id: new_id for new_id, old_id in enumerate(labels_list)} # –†–∞–∑–º–µ—á–∞–µ–º –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è yolo –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "# –≤—ã–≤–æ–¥ —Å–ª–æ–≤–∞—Ä—è\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = \"D:\\\\data science\\\\B\\\\data\\\\train\\\\labels\"\n",
    "\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    file_path = os.path.join(labels_dir, label_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        class_id = int(parts[0])\n",
    "        if class_id in mapping:\n",
    "            parts[0] = str(mapping[class_id])  # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π ID –Ω–∞ –Ω–æ–≤—ã–π\n",
    "            new_lines.append(\" \".join(parts))\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.writelines(\"\\n\".join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = \"D:\\\\data science\\\\B\\\\data\\\\val\\\\labels\"\n",
    "\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    file_path = os.path.join(labels_dir, label_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        class_id = int(parts[0])\n",
    "        if class_id in mapping:\n",
    "            parts[0] = str(mapping[class_id])  # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π ID –Ω–∞ –Ω–æ–≤—ã–π\n",
    "            new_lines.append(\" \".join(parts))\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.writelines(\"\\n\".join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ YAML –æ–±–Ω–æ–≤–ª–µ–Ω!\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'train': 'data/train/images',\n",
    "    'val': 'data/val/images',\n",
    "    'nc': len(labels_list),  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å 3483\n",
    "    'names': [str(x) for x in labels_list],  # –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω –∫–ª–∞—Å—Å–æ–≤ (–≤ –ø–æ—Ä—è–¥–∫–µ –æ—Ç 0 –¥–æ 3482)\n",
    "    'train_labels': 'data/train/labels',\n",
    "    'val_labels': 'data/val/labels'\n",
    "}\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ YAML\n",
    "import yaml\n",
    "with open('yolo_config_fixed.yaml', 'w') as file:\n",
    "    yaml.dump(data, file, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "print(\"‚úÖ YAML –æ–±–Ω–æ–≤–ª–µ–Ω!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "\n",
    "# # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ YOLO\n",
    "# data = {\n",
    "#     'train': 'data/train/images',  # –ø—É—Ç—å –∫ –æ–±—É—á–∞—é—â–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º\n",
    "#     'val': 'data/val/images',  # –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "#     'nc': len(labels_list),  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤\n",
    "#     'names': labels_list,  # –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "#     'train_labels': 'data/train/labels',  # –ø—É—Ç—å –∫ –º–µ—Ç–∫–∞–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "#     'val_labels': 'data/val/labels'  # –ø—É—Ç—å –∫ –º–µ—Ç–∫–∞–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "# }\n",
    "\n",
    "# # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ YAML —Ñ–∞–π–ª\n",
    "# with open('yolo_config2test.yaml', 'w') as file:\n",
    "#     yaml.dump(data, file, default_flow_style=True, allow_unicode=True)\n",
    "\n",
    "# print(\"YAML —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, data_yaml):\n",
    "    model = YOLO(model_name)\n",
    "    training_results = model.train(\n",
    "        data=data_yaml,\n",
    "        epochs=5, # —á–∏—Å–ª–æ —ç–ø–æ—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        imgsz=240, # —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        batch=16, # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        device=0, # –Ω–æ–º–µ—Ä –¥–µ–≤–∞–π—Å–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        single_cls=False # –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ data.yaml\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.75 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.12.7 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=D:\\data science\\B\\images_v2\\yolov8m.pt, data=D:\\data science\\B\\yolo_config_fixed.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=240, save=True, save_period=-1, val_period=1, cache=False, device=0, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=3484\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5792932  ultralytics.nn.modules.head.Detect           [3484, [192, 384, 576]]       \n",
      "Model summary: 295 layers, 27873556 parameters, 27873540 gradients, 90.3 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "WARNING ‚ö†Ô∏è imgsz=[240] must be multiple of max stride 32, updating to [256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\data science\\B\\data\\train\\labels.cache... 9356 images, 2282 backgrounds, 5 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9357/9357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è D:\\data science\\B\\data\\train\\images\\frame_1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        529         178         133         133]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è D:\\data science\\B\\data\\train\\images\\frame_11.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        296         114         158         158]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è D:\\data science\\B\\data\\train\\images\\frame_12.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        339         120         158         158]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è D:\\data science\\B\\data\\train\\images\\frame_14.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        429         141         139         139]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è D:\\data science\\B\\data\\train\\images\\frame_16.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        286         132         149         149]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
      "UserWarning: Got processor for bboxes, but no transform to process it.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata science\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mimages_v2\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43myolov8m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata science\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43myolo_config_fixed.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model_name, data_yaml)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model_name, data_yaml):\n\u001b[0;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m YOLO(model_name)\n\u001b[1;32m----> 3\u001b[0m     training_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# —á–∏—Å–ª–æ —ç–ø–æ—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m240\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# –Ω–æ–º–µ—Ä –¥–µ–≤–∞–π—Å–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ data.yaml\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\ultralytics\\engine\\model.py:657\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:213\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:327\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[0;32m    330\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:291\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# Dataloaders\u001b[39;00m\n\u001b[0;32m    290\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(world_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:55\u001b[0m, in \u001b[0;36mDetectionTrainer.get_dataloader\u001b[1;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[0;32m     53\u001b[0m     shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     54\u001b[0m workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\ultralytics\\data\\build.py:114\u001b[0m, in \u001b[0;36mbuild_dataloader\u001b[1;34m(dataset, batch, workers, shuffle, rank)\u001b[0m\n\u001b[0;32m    112\u001b[0m generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator()\n\u001b[0;32m    113\u001b[0m generator\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m6148914691236517205\u001b[39m \u001b[38;5;241m+\u001b[39m RANK)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInfiniteDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIN_MEMORY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollate_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker_init_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\ultralytics\\data\\build.py:40\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_sampler\u001b[39m\u001b[38;5;124m\"\u001b[39m, _RepeatSampler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sampler))\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:484\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1131\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\"D:\\\\data science\\\\B\\\\images_v2\\\\yolov8m.pt\", \"D:\\\\data science\\\\B\\\\yolo_config_fixed.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r'D:\\data science\\B\\runs\\detect\\train\\weights\\best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\data science\\B\\data\\val\\images\\000008.jpg: 256x192 (no detections), 55.4ms\n",
      "Speed: 1.0ms preprocess, 55.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 192)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = model.predict(r\"D:\\data science\\B\\data\\val\\images\\000008.jpg\")\n",
    "img_masks = result[0].plot(boxes=True, labels=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sv.plot_image(img_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(\"output.jpg\", img_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–∞–º—Å–∫–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = r\"D:\\data science\\B\\images2\"\n",
    "LABELS_FOLDER = r\"D:\\data science\\B\\labels_bbox\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image)  # –£–±–∏—Ä–∞–µ–º unsqueeze(0), —á—Ç–æ–±—ã –±—ã–ª–æ 3D\n",
    "\n",
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, image_folder, labels_folder):\n",
    "        self.image_folder = image_folder\n",
    "        self.labels_folder = labels_folder\n",
    "        self.image_files = os.listdir(image_folder)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img1_name = self.image_files[idx]\n",
    "        img2_name = np.random.choice(self.image_files)\n",
    "\n",
    "        img1 = self.transform(Image.open(os.path.join(self.image_folder, img1_name)).convert('RGB'))\n",
    "        img2 = self.transform(Image.open(os.path.join(self.image_folder, img2_name)).convert('RGB'))\n",
    "\n",
    "        with open(os.path.join(self.labels_folder, img1_name.replace('.jpg', '.txt')), 'r') as f:\n",
    "            label1 = int(f.readline().split()[0])\n",
    "        \n",
    "        with open(os.path.join(self.labels_folder, img2_name.replace('.jpg', '.txt')), 'r') as f:\n",
    "            label2 = int(f.readline().split()[0])\n",
    "\n",
    "        same_class = torch.tensor(1.0 if label1 == label2 else 0.0)\n",
    "        return img1, img2, same_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Linear(512, 256)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img1, img2):\n",
    "        out1 = self.cnn(img1)\n",
    "        out2 = self.cnn(img2)\n",
    "        combined = torch.cat((out1, out2), dim=1)\n",
    "        return self.fc(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_dataset = SiameseDataset(IMAGE_FOLDER, LABELS_FOLDER)\n",
    "dataloader = DataLoader(siamese_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model = SiameseNetwork().cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f86bcd906e49ac9df653c6e24c4c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.0143\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for img1, img2, labels in tqdm(dataloader):\n",
    "        img1, img2, labels = img1.cuda(), img2.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img1, img2).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"siamese_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image2(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0) # –î–æ–±–∞–≤–ª—è–µ–º batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER2 = r\"D:\\data science\\B\\images2\"\n",
    "LABELS_FOLDER2 = r\"D:\\data science\\B\\labels_bbox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e5abecea7744508bb81bdc41b858ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∫ –∫–ª–∞—Å—Å—É: 407\n"
     ]
    }
   ],
   "source": [
    "def predict_class(test_img_path, model_path=\"siamese_model.pth\"):\n",
    "    model = SiameseNetwork().cuda()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    test_img = load_image2(test_img_path).cuda()\n",
    "    max_similarity = 0\n",
    "    best_class = None\n",
    "    \n",
    "    for img_name in tqdm(os.listdir(IMAGE_FOLDER2)):\n",
    "        img_path = os.path.join(IMAGE_FOLDER2, img_name)\n",
    "        label_path = os.path.join(LABELS_FOLDER2, img_name.replace('.jpg', '.txt'))\n",
    "        \n",
    "        ref_img = load_image2(img_path).cuda()\n",
    "        with open(label_path, 'r') as f:\n",
    "            first_line = f.readline().strip()\n",
    "            label = int(first_line.split()[0]) if first_line else 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            similarity = model(test_img, ref_img).item()\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_class = label\n",
    "    \n",
    "    return best_class\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "img_test =r\"D:\\data science\\world_skils\\osn\\images_v2\\images\\000008.jpg\"\n",
    "predicted_class = predict_class(img_test)\n",
    "print(f\"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∫ –∫–ª–∞—Å—Å—É: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f3aad1b6b44a459b17b91f8dfcba06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img1, img2, labels in tqdm(dataloader):\n",
    "            img1, img2, labels = img1.cuda(), img2.cuda(), labels.cuda()\n",
    "            outputs = model(img1, img2).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            preds = (outputs > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "        avg_loss = val_loss / len(dataloader)\n",
    "        accuracy = correct / total\n",
    "        losses.append(avg_loss)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    return losses, accuracies\n",
    "\n",
    "# –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "val_losses, val_accuracies = validate_model(model, dataloader, criterion)\n",
    "\n",
    "def plot_metrics(val_losses, val_accuracies):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    ax1.plot(val_losses, 'r-', label='Validation Loss')\n",
    "    ax2.plot(val_accuracies, 'b-', label='Validation Accuracy')\n",
    "    \n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color='r')\n",
    "    ax2.set_ylabel('Accuracy', color='b')\n",
    "    \n",
    "    plt.title('Validation Metrics')\n",
    "    fig.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(val_losses, val_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
